{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa09775-fa9e-4fe6-894a-703e4216a5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-1.1.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers>=4.36.0\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting peft\n",
      "  Downloading peft-0.17.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting trl\n",
      "  Downloading trl-0.25.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: jsonschema in /opt/app-root/lib64/python3.12/site-packages (4.25.1)\n",
      "Collecting litellm\n",
      "  Downloading litellm-1.79.1-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: jinja2>=3.1.0 in /opt/app-root/lib64/python3.12/site-packages (3.1.6)\n",
      "Collecting torch>=2.0.0\n",
      "  Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting openai\n",
      "  Downloading openai-2.7.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: jupyterlab in /opt/app-root/lib64/python3.12/site-packages (4.4.7)\n",
      "Collecting llama-stack>=0.2.17\n",
      "  Downloading llama_stack-0.3.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting sqlalchemy\n",
      "  Downloading sqlalchemy-2.0.44-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting greenlet\n",
      "  Downloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
      "Collecting aiosqlite\n",
      "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting opentelemetry-sdk\n",
      "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-api\n",
      "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp\n",
      "  Downloading opentelemetry_exporter_otlp-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting mcp\n",
      "  Downloading mcp-1.20.0-py3-none-any.whl.metadata (85 kB)\n",
      "Collecting filelock (from huggingface_hub)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub)\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface_hub)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/app-root/lib64/python3.12/site-packages (from huggingface_hub) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/app-root/lib64/python3.12/site-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib64/python3.12/site-packages (from huggingface_hub) (6.0.2)\n",
      "Collecting shellingham (from huggingface_hub)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting tqdm>=4.42.1 (from huggingface_hub)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typer-slim (from huggingface_hub)\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib64/python3.12/site-packages (from huggingface_hub) (4.15.0)\n",
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy>=1.17 (from transformers>=4.36.0)\n",
      "  Downloading numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.36.0)\n",
      "  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib64/python3.12/site-packages (from transformers>=4.36.0) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers>=4.36.0)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers>=4.36.0)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: psutil in /opt/app-root/lib64/python3.12/site-packages (from peft) (7.0.0)\n",
      "Collecting accelerate>=0.21.0 (from peft)\n",
      "  Downloading accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/app-root/lib64/python3.12/site-packages (from jsonschema) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/app-root/lib64/python3.12/site-packages (from jsonschema) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/app-root/lib64/python3.12/site-packages (from jsonschema) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/app-root/lib64/python3.12/site-packages (from jsonschema) (0.27.1)\n",
      "Requirement already satisfied: aiohttp>=3.10 in /opt/app-root/lib64/python3.12/site-packages (from litellm) (3.12.15)\n",
      "Collecting click (from litellm)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fastuuid>=0.13.0 (from litellm)\n",
      "  Downloading fastuuid-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting importlib-metadata>=6.8.0 (from litellm)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting pydantic<3.0.0,>=2.5.0 (from litellm)\n",
      "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Collecting python-dotenv>=0.2.0 (from litellm)\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting tiktoken>=0.7.0 (from litellm)\n",
      "  Downloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib64/python3.12/site-packages (from jinja2>=3.1.0) (3.0.2)\n",
      "Requirement already satisfied: setuptools in /opt/app-root/lib64/python3.12/site-packages (from torch>=2.0.0) (80.9.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.0.0)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch>=2.0.0)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.0.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.0.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.0.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.0.0)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.0.0)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.0.0)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.0.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.0.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.0.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.0.0)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch>=2.0.0)\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch>=2.0.0)\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.0.0)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.0.0)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.0.0)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.0 (from torch>=2.0.0)\n",
      "  Downloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/app-root/lib64/python3.12/site-packages (from openai) (4.10.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.11.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /opt/app-root/lib64/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/app-root/lib64/python3.12/site-packages (from jupyterlab) (2.0.5)\n",
      "Requirement already satisfied: ipykernel!=6.30.0,>=6.5.0 in /opt/app-root/lib64/python3.12/site-packages (from jupyterlab) (6.30.1)\n",
      "Requirement already satisfied: jupyter-core in /opt/app-root/lib64/python3.12/site-packages (from jupyterlab) (5.8.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/app-root/lib64/python3.12/site-packages (from jupyterlab) (2.3.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/app-root/lib64/python3.12/site-packages (from jupyterlab) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /opt/app-root/lib64/python3.12/site-packages (from jupyterlab) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /opt/app-root/lib64/python3.12/site-packages (from jupyterlab) (0.2.4)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /opt/app-root/lib64/python3.12/site-packages (from jupyterlab) (6.5.2)\n",
      "Requirement already satisfied: traitlets in /opt/app-root/lib64/python3.12/site-packages (from jupyterlab) (5.14.3)\n",
      "Collecting fastapi<1.0,>=0.115.0 (from llama-stack>=0.2.17)\n",
      "  Downloading fastapi-0.121.0-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting fire (from llama-stack>=0.2.17)\n",
      "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting llama-stack-client>=0.3.1 (from llama-stack>=0.2.17)\n",
      "  Downloading llama_stack_client-0.3.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: prompt-toolkit in /opt/app-root/lib64/python3.12/site-packages (from llama-stack>=0.2.17) (3.0.52)\n",
      "Collecting pyjwt>=2.10.0 (from pyjwt[crypto]>=2.10.0->llama-stack>=0.2.17)\n",
      "  Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting rich (from llama-stack>=0.2.17)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting starlette (from llama-stack>=0.2.17)\n",
      "  Downloading starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting termcolor (from llama-stack>=0.2.17)\n",
      "  Downloading termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting pillow (from llama-stack>=0.2.17)\n",
      "  Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: h11>=0.16.0 in /opt/app-root/lib64/python3.12/site-packages (from llama-stack>=0.2.17) (0.16.0)\n",
      "Collecting python-multipart>=0.0.20 (from llama-stack>=0.2.17)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting uvicorn>=0.34.0 (from llama-stack>=0.2.17)\n",
      "  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http>=1.30.0 (from llama-stack>=0.2.17)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting asyncpg (from llama-stack>=0.2.17)\n",
      "  Downloading asyncpg-0.30.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk)\n",
      "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc==1.38.0 (from opentelemetry-exporter-otlp)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc==1.38.0->opentelemetry-exporter-otlp)\n",
      "  Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting grpcio<2.0.0,>=1.63.2 (from opentelemetry-exporter-otlp-proto-grpc==1.38.0->opentelemetry-exporter-otlp)\n",
      "  Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc==1.38.0->opentelemetry-exporter-otlp)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc==1.38.0->opentelemetry-exporter-otlp)\n",
      "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf<7.0,>=5.0 (from opentelemetry-proto==1.38.0->opentelemetry-exporter-otlp-proto-grpc==1.38.0->opentelemetry-exporter-otlp)\n",
      "  Downloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting httpx-sse>=0.4 (from mcp)\n",
      "  Downloading httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting pydantic-settings>=2.5.2 (from mcp)\n",
      "  Downloading pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting sse-starlette>=1.6.1 (from mcp)\n",
      "  Downloading sse_starlette-3.0.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp>=3.10->litellm) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp>=3.10->litellm) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp>=3.10->litellm) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp>=3.10->litellm) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp>=3.10->litellm) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp>=3.10->litellm) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/app-root/lib64/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Collecting starlette (from llama-stack>=0.2.17)\n",
      "  Downloading starlette-0.49.3-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi<1.0,>=0.115.0->llama-stack>=0.2.17)\n",
      "  Downloading annotated_doc-0.0.3-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: certifi in /opt/app-root/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface_hub) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface_hub) (1.0.9)\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=6.8.0->litellm)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/app-root/lib64/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/app-root/lib64/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (1.8.16)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/app-root/lib64/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (9.5.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in /opt/app-root/lib64/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (8.6.3)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/app-root/lib64/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in /opt/app-root/lib64/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=25 in /opt/app-root/lib64/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (27.1.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/app-root/lib64/python3.12/site-packages (from jupyter-core->jupyterlab) (4.4.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /opt/app-root/lib64/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (25.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /opt/app-root/lib64/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /opt/app-root/lib64/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /opt/app-root/lib64/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /opt/app-root/lib64/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /opt/app-root/lib64/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.22.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /opt/app-root/lib64/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/app-root/lib64/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /opt/app-root/lib64/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/app-root/lib64/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/app-root/lib64/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.12.1)\n",
      "Collecting pyaml (from llama-stack-client>=0.3.1->llama-stack>=0.2.17)\n",
      "  Downloading pyaml-25.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.5.0->litellm)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3.0.0,>=2.5.0->litellm)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.5.0->litellm)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting cryptography>=3.4.0 (from pyjwt[crypto]>=2.10.0->llama-stack>=0.2.17)\n",
      "  Downloading cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/app-root/lib64/python3.12/site-packages (from requests->transformers>=4.36.0) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.12/site-packages (from requests->transformers>=4.36.0) (2.5.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.0.0)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib64/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: wcwidth in /opt/app-root/lib64/python3.12/site-packages (from prompt-toolkit->llama-stack>=0.2.17) (0.2.13)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->llama-stack>=0.2.17)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/app-root/lib64/python3.12/site-packages (from rich->llama-stack>=0.2.17) (2.19.2)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/app-root/lib64/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (25.1.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /opt/app-root/lib64/python3.12/site-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.0->llama-stack>=0.2.17) (2.0.0)\n",
      "Requirement already satisfied: decorator in /opt/app-root/lib64/python3.12/site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /opt/app-root/lib64/python3.12/site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/app-root/lib64/python3.12/site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/app-root/lib64/python3.12/site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (4.9.0)\n",
      "Requirement already satisfied: stack_data in /opt/app-root/lib64/python3.12/site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.6.3)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/app-root/lib64/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.3.0)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/app-root/lib64/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/app-root/lib64/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->llama-stack>=0.2.17)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/app-root/lib64/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.13.5)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/app-root/lib64/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /opt/app-root/lib64/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/app-root/lib64/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/app-root/lib64/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/app-root/lib64/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/app-root/lib64/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/app-root/lib64/python3.12/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.21.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: ptyprocess in /opt/app-root/lib64/python3.12/site-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.0)\n",
      "Requirement already satisfied: webencodings in /opt/app-root/lib64/python3.12/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /opt/app-root/lib64/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.4.0)\n",
      "Requirement already satisfied: pycparser in /opt/app-root/lib64/python3.12/site-packages (from cffi>=2.0.0->cryptography>=3.4.0->pyjwt[crypto]>=2.10.0->llama-stack>=0.2.17) (2.23)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/app-root/lib64/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.8.5)\n",
      "Requirement already satisfied: fqdn in /opt/app-root/lib64/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/app-root/lib64/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/app-root/lib64/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /opt/app-root/lib64/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.1.0)\n",
      "Requirement already satisfied: uri-template in /opt/app-root/lib64/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /opt/app-root/lib64/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (24.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/app-root/lib64/python3.12/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.8)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/app-root/lib64/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/app-root/lib64/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /opt/app-root/lib64/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.2.3)\n",
      "Requirement already satisfied: lark>=1.2.2 in /opt/app-root/lib64/python3.12/site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.2.2)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/app-root/lib64/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/app-root/lib64/python3.12/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.9.0.20250822)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.17.1-py3-none-any.whl (504 kB)\n",
      "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "Downloading trl-0.25.0-py3-none-any.whl (462 kB)\n",
      "Downloading litellm-1.79.1-py3-none-any.whl (10.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-2.7.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_stack-0.3.1-py3-none-any.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sqlalchemy-2.0.44-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (607 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m607.6/607.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
      "Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
      "Downloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
      "Downloading opentelemetry_exporter_otlp-1.38.0-py3-none-any.whl (7.0 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.38.0-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
      "Downloading mcp-1.20.0-py3-none-any.whl (173 kB)\n",
      "Downloading accelerate-1.11.0-py3-none-any.whl (375 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading fastapi-0.121.0-py3-none-any.whl (109 kB)\n",
      "Downloading fastuuid-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\n",
      "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading jiter-0.11.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (358 kB)\n",
      "Downloading llama_stack_client-0.3.1-py3-none-any.whl (425 kB)\n",
      "Downloading multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
      "Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading sse_starlette-3.0.3-py3-none-any.whl (11 kB)\n",
      "Downloading starlette-0.49.3-py3-none-any.whl (74 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading asyncpg-0.30.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
      "Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Downloading annotated_doc-0.0.3-py3-none-any.whl (5.5 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading pyaml-25.7.0-py3-none-any.whl (26 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Installing collected packages: pytz, nvidia-cusparselt-cu12, mpmath, zipp, xxhash, tzdata, typing-inspection, triton, tqdm, termcolor, sympy, safetensors, regex, python-multipart, python-dotenv, pyjwt, pydantic-core, pyarrow, pyaml, protobuf, pillow, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, mdurl, jiter, httpx-sse, hf-xet, grpcio, greenlet, fsspec, filelock, fastuuid, distro, dill, click, asyncpg, annotated-types, annotated-doc, aiosqlite, uvicorn, tiktoken, starlette, sse-starlette, sqlalchemy, pydantic, pandas, opentelemetry-proto, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, multiprocess, markdown-it-py, importlib-metadata, huggingface_hub, googleapis-common-protos, fire, faiss-cpu, cryptography, tokenizers, rich, pydantic-settings, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, openai, nvidia-cusolver-cu12, fastapi, transformers, torch, opentelemetry-semantic-conventions, mcp, llama-stack-client, litellm, datasets, opentelemetry-sdk, accelerate, trl, peft, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-exporter-otlp, llama-stack\n",
      "Successfully installed accelerate-1.11.0 aiosqlite-0.21.0 annotated-doc-0.0.3 annotated-types-0.7.0 asyncpg-0.30.0 click-8.3.0 cryptography-46.0.3 datasets-4.4.1 dill-0.4.0 distro-1.9.0 faiss-cpu-1.12.0 fastapi-0.121.0 fastuuid-0.14.0 filelock-3.20.0 fire-0.7.1 fsspec-2025.10.0 googleapis-common-protos-1.72.0 greenlet-3.2.4 grpcio-1.76.0 hf-xet-1.2.0 httpx-sse-0.4.3 huggingface_hub-0.36.0 importlib-metadata-8.7.0 jiter-0.11.1 litellm-1.79.1 llama-stack-0.3.1 llama-stack-client-0.3.1 markdown-it-py-4.0.0 mcp-1.20.0 mdurl-0.1.2 mpmath-1.3.0 multiprocess-0.70.18 networkx-3.5 numpy-2.3.4 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 openai-2.7.1 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-exporter-otlp-proto-http-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 pandas-2.3.3 peft-0.17.1 pillow-12.0.0 protobuf-6.33.0 pyaml-25.7.0 pyarrow-22.0.0 pydantic-2.12.4 pydantic-core-2.41.5 pydantic-settings-2.11.0 pyjwt-2.10.1 python-dotenv-1.2.1 python-multipart-0.0.20 pytz-2025.2 regex-2025.11.3 rich-14.2.0 safetensors-0.6.2 sqlalchemy-2.0.44 sse-starlette-3.0.3 starlette-0.49.3 sympy-1.14.0 termcolor-3.2.0 tiktoken-0.12.0 tokenizers-0.22.1 torch-2.9.0 tqdm-4.67.1 transformers-4.57.1 triton-3.5.0 trl-0.25.0 typing-inspection-0.4.2 tzdata-2025.2 uvicorn-0.38.0 xxhash-3.6.0 zipp-3.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required Python packages for this notebook environment\n",
    "%pip install \\\n",
    "  huggingface_hub \\\n",
    "  \"transformers>=4.36.0\" \\\n",
    "  peft \\\n",
    "  datasets \\\n",
    "  trl \\\n",
    "  jsonschema \\\n",
    "  litellm \\\n",
    "  \"jinja2>=3.1.0\" \\\n",
    "  \"torch>=2.0.0\" \\\n",
    "  openai \\\n",
    "  jupyterlab \\\n",
    "  \"llama-stack>=0.2.17\" \\\n",
    "  \"sqlalchemy\" \\\n",
    "  \"greenlet\" \\\n",
    "  \"faiss-cpu\" \\\n",
    "  \"aiosqlite\" \\\n",
    "  \"opentelemetry-sdk\" \\\n",
    "  \"opentelemetry-api\" \\\n",
    "  \"opentelemetry-exporter-otlp\" \\\n",
    "  \"mcp\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6078483b-d14e-4c55-b5d1-526271f9e271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from pprint import pprint\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ce11ce2-5473-40e3-8061-9c235a2b5de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "# Limits to at most N tool properties\n",
    "LIMIT_TOOL_PROPERTIES = 8\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b23498e3-c932-40a9-8c21-234bd4e4f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processed data will be stored here\n",
    "DATA_ROOT = os.path.join(os.getcwd(), \"sample_data\")\n",
    "CUSTOMIZATION_DATA_ROOT = os.path.join(DATA_ROOT, \"customization\")\n",
    "VALIDATION_DATA_ROOT = os.path.join(DATA_ROOT, \"validation\")\n",
    "EVALUATION_DATA_ROOT = os.path.join(DATA_ROOT, \"evaluation\")\n",
    "\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "os.makedirs(CUSTOMIZATION_DATA_ROOT, exist_ok=True)\n",
    "os.makedirs(VALIDATION_DATA_ROOT, exist_ok=True)\n",
    "os.makedirs(EVALUATION_DATA_ROOT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ac5278-84a0-4c80-b80f-48679e4b1107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import HF_TOKEN\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://huggingface.co\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d5368b5-13ca-455c-88f4-f5f1d8da62b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 60000/60000 [00:00<00:00, 124545.55 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answers': '[{\"name\": \"live_giveaways_by_type\", \"arguments\": {\"type\": '\n",
      "            '\"beta\"}}, {\"name\": \"live_giveaways_by_type\", \"arguments\": '\n",
      "            '{\"type\": \"game\"}}]',\n",
      " 'id': 0,\n",
      " 'query': 'Where can I find live giveaways for beta access and games?',\n",
      " 'tools': '[{\"name\": \"live_giveaways_by_type\", \"description\": \"Retrieve live '\n",
      "          'giveaways from the GamerPower API based on the specified type.\", '\n",
      "          '\"parameters\": {\"type\": {\"description\": \"The type of giveaways to '\n",
      "          'retrieve (e.g., game, loot, beta).\", \"type\": \"str\", \"default\": '\n",
      "          '\"game\"}}}]'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download from Hugging Face\n",
    "dataset = load_dataset(\"Salesforce/xlam-function-calling-60k\")\n",
    "\n",
    "# Inspect a sample\n",
    "example = dataset['train'][0]\n",
    "pprint(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b25805cf-a631-4f21-b1f7-60dd843ea422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_type(param_type: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize Python type hints and parameter definitions to OpenAI function spec types.\n",
    "\n",
    "    Args:\n",
    "        param_type: Type string that could include default values or complex types\n",
    "\n",
    "    Returns:\n",
    "        Normalized type string according to OpenAI function spec\n",
    "    \"\"\"\n",
    "    # Remove whitespace\n",
    "    param_type = param_type.strip()\n",
    "\n",
    "    # Handle types with default values (e.g. \"str, default='London'\")\n",
    "    if \",\" in param_type and \"default\" in param_type:\n",
    "        param_type = param_type.split(\",\")[0].strip()\n",
    "\n",
    "    # Handle types with just default values (e.g. \"default='London'\")\n",
    "    if param_type.startswith(\"default=\"):\n",
    "        return \"string\"  # Default to string if only default value is given\n",
    "\n",
    "    # Remove \", optional\" suffix if present\n",
    "    param_type = param_type.replace(\", optional\", \"\").strip()\n",
    "\n",
    "    # Handle complex types\n",
    "    if param_type.startswith(\"Callable\"):\n",
    "        return \"string\"  # Represent callable as string in JSON schema\n",
    "    if param_type.startswith(\"Tuple\"):\n",
    "        return \"array\"  # Represent tuple as array in JSON schema\n",
    "    if param_type.startswith(\"List[\"):\n",
    "        return \"array\"\n",
    "    if param_type.startswith(\"Set\") or param_type == \"set\":\n",
    "        return \"array\"  # Represent set as array in JSON schema\n",
    "\n",
    "    # Map common type variations to OpenAI spec types\n",
    "    type_mapping: Dict[str, str] = {\n",
    "        \"str\": \"string\",\n",
    "        \"int\": \"integer\",\n",
    "        \"float\": \"number\",\n",
    "        \"bool\": \"boolean\",\n",
    "        \"list\": \"array\",\n",
    "        \"dict\": \"object\",\n",
    "        \"List\": \"array\",\n",
    "        \"Dict\": \"object\",\n",
    "        \"set\": \"array\",\n",
    "        \"Set\": \"array\"\n",
    "    }\n",
    "\n",
    "    if param_type in type_mapping:\n",
    "        return type_mapping[param_type]\n",
    "    else:\n",
    "        print(f\"Unknown type: {param_type}\")\n",
    "        return \"string\"  # Default to string for unknown types\n",
    "\n",
    "\n",
    "def convert_tools_to_openai_spec(tools: Union[str, List[Dict[str, Any]]]) -> List[Dict[str, Any]]:\n",
    "    # If tools is a string, try to parse it as JSON\n",
    "    if isinstance(tools, str):\n",
    "        try:\n",
    "            tools = json.loads(tools)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Failed to parse tools string as JSON: {e}\")\n",
    "            return []\n",
    "\n",
    "    # Ensure tools is a list\n",
    "    if not isinstance(tools, list):\n",
    "        print(f\"Expected tools to be a list, but got {type(tools)}\")\n",
    "        return []\n",
    "\n",
    "    openai_tools: List[Dict[str, Any]] = []\n",
    "    for tool in tools:\n",
    "        # Check if tool is a dictionary\n",
    "        if not isinstance(tool, dict):\n",
    "            print(f\"Expected tool to be a dictionary, but got {type(tool)}\")\n",
    "            continue\n",
    "\n",
    "        # Check if 'parameters' is a dictionary\n",
    "        if not isinstance(tool.get(\"parameters\"), dict):\n",
    "            print(f\"Expected 'parameters' to be a dictionary, but got {type(tool.get('parameters'))} for tool: {tool}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "        normalized_parameters: Dict[str, Dict[str, Any]] = {}\n",
    "        for param_name, param_info in tool[\"parameters\"].items():\n",
    "            if not isinstance(param_info, dict):\n",
    "                print(\n",
    "                    f\"Expected parameter info to be a dictionary, but got {type(param_info)} for parameter: {param_name}\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Create parameter info without default first\n",
    "            param_dict = {\n",
    "                \"description\": param_info.get(\"description\", \"\"),\n",
    "                \"type\": normalize_type(param_info.get(\"type\", \"\")),\n",
    "            }\n",
    "\n",
    "            # Only add default if it exists, is not None, and is not an empty string\n",
    "            default_value = param_info.get(\"default\")\n",
    "            if default_value is not None and default_value != \"\":\n",
    "                param_dict[\"default\"] = default_value\n",
    "\n",
    "            normalized_parameters[param_name] = param_dict\n",
    "\n",
    "        openai_tool = {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": tool[\"name\"],\n",
    "                \"description\": tool[\"description\"],\n",
    "                \"parameters\": {\"type\": \"object\", \"properties\": normalized_parameters},\n",
    "            },\n",
    "        }\n",
    "        openai_tools.append(openai_tool)\n",
    "    return openai_tools\n",
    "\n",
    "\n",
    "def save_jsonl(filename, data):\n",
    "    \"\"\"Write a list of json objects to a .jsonl file\"\"\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        for entry in data:\n",
    "            f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "\n",
    "def convert_tool_calls(xlam_tools):\n",
    "    \"\"\"Convert XLAM tool format to OpenAI's tool schema.\"\"\"\n",
    "    tools = []\n",
    "    for tool in json.loads(xlam_tools):\n",
    "        tools.append({\"type\": \"function\", \"function\": {\"name\": tool[\"name\"], \"arguments\": tool.get(\"arguments\", {})}})\n",
    "    return tools\n",
    "\n",
    "\n",
    "def convert_example(example, dataset_type='single'):\n",
    "    \"\"\"Convert an XLAM dataset example to OpenAI format.\"\"\"\n",
    "    obj = {\"messages\": []}\n",
    "\n",
    "    # User message\n",
    "    obj[\"messages\"].append({\"role\": \"user\", \"content\": example[\"query\"]})\n",
    "\n",
    "    # Tools\n",
    "    if example.get(\"tools\"):\n",
    "        obj[\"tools\"] = convert_tools_to_openai_spec(example[\"tools\"])\n",
    "\n",
    "    # Assistant message\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    if example.get(\"answers\"):\n",
    "        tool_calls = convert_tool_calls(example[\"answers\"])\n",
    "\n",
    "        if dataset_type == \"single\":\n",
    "            # Only include examples with a single tool call\n",
    "            if len(tool_calls) == 1:\n",
    "                assistant_message[\"tool_calls\"] = tool_calls\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            # For other dataset types, include all tool calls\n",
    "            assistant_message[\"tool_calls\"] = tool_calls\n",
    "\n",
    "    obj[\"messages\"].append(assistant_message)\n",
    "\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "744add64-3469-41d6-a79a-2a923566a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_example(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d06143b2-8122-4ee4-870f-4432d844f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_examples = []\n",
    "with open(os.path.join(DATA_ROOT, \"xlam_openai_format.jsonl\"), \"w\") as f:\n",
    "    for example in dataset[\"train\"]:\n",
    "        converted = convert_example(example)\n",
    "        if converted is not None:\n",
    "            all_examples.append(converted)\n",
    "            f.write(json.dumps(converted) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7fa544a-984f-46ac-893d-777b836c3d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXAMPLES = 5000\n",
    "\n",
    "assert NUM_EXAMPLES <= len(all_examples), f\"{NUM_EXAMPLES} exceeds the total number of available ({len(all_examples)}) data points\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fed6a264-6570-4df6-bdd1-5e742582dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_examples = random.sample(all_examples, NUM_EXAMPLES)\n",
    "\n",
    "# Split into 70% training, 15% validation, 15% testing\n",
    "train_size = int(0.7 * len(sampled_examples))\n",
    "val_size = int(0.15 * len(sampled_examples))\n",
    "\n",
    "train_data = sampled_examples[:train_size]\n",
    "val_data = sampled_examples[train_size : train_size + val_size]\n",
    "test_data = sampled_examples[train_size + val_size :]\n",
    "\n",
    "# Save the training and validation splits. We will use test split in the next section\n",
    "save_jsonl(os.path.join(CUSTOMIZATION_DATA_ROOT, \"training.jsonl\"), train_data)\n",
    "save_jsonl(os.path.join(VALIDATION_DATA_ROOT,\"validation.jsonl\"), val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcc9cbfc-8e07-4f9a-8843-b9cf7937c39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_example_eval(entry):\n",
    "    \"\"\"Convert a single entry in the dataset to the evaluator format\"\"\"\n",
    "\n",
    "    # Note: This is a WAR for a known bug with tool calling in NIM\n",
    "    for tool in entry[\"tools\"]:\n",
    "        if len(tool[\"function\"][\"parameters\"][\"properties\"]) > LIMIT_TOOL_PROPERTIES:\n",
    "            return None\n",
    "\n",
    "    new_entry = {\n",
    "        \"messages\": [],\n",
    "        \"tools\": entry[\"tools\"],\n",
    "        \"tool_calls\": []\n",
    "    }\n",
    "\n",
    "    for msg in entry[\"messages\"]:\n",
    "        if msg[\"role\"] == \"assistant\" and \"tool_calls\" in msg:\n",
    "            new_entry[\"tool_calls\"] = msg[\"tool_calls\"]\n",
    "        else:\n",
    "            new_entry[\"messages\"].append(msg)\n",
    "\n",
    "    return new_entry\n",
    "\n",
    "def convert_dataset_eval(data):\n",
    "    \"\"\"Convert the entire dataset for evaluation by restructuring the data format.\"\"\"\n",
    "    return [result for entry in data if (result := convert_example_eval(entry)) is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7348e70e-2155-4e00-a75f-123b9e24e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_eval = convert_dataset_eval(test_data)\n",
    "save_jsonl(os.path.join(EVALUATION_DATA_ROOT, \"xlam-test-single.jsonl\"), test_data_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af22882b-6f2f-492e-95cd-4bb817826af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e098cfd-42be-416d-8118-70f449f613d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata associated with Datasets and Customization Jobs\n",
    "os.environ[\"NVIDIA_DATASET_NAMESPACE\"] = NMS_NAMESPACE\n",
    "os.environ[\"NVIDIA_PROJECT_ID\"] = PROJECT_ID\n",
    "\n",
    "## Inference env vars\n",
    "os.environ[\"NVIDIA_BASE_URL\"] = NIM_URL\n",
    "\n",
    "# Data Store env vars\n",
    "os.environ[\"NVIDIA_DATASETS_URL\"] = ENTITY_STORE_URL\n",
    "\n",
    "## Customizer env vars\n",
    "os.environ[\"NVIDIA_CUSTOMIZER_URL\"] = CUSTOMIZER_URL\n",
    "os.environ[\"NVIDIA_OUTPUT_MODEL_DIR\"] = CUSTOMIZED_MODEL_DIR\n",
    "\n",
    "# Evaluator env vars\n",
    "os.environ[\"NVIDIA_EVALUATOR_URL\"] = EVALUATOR_URL\n",
    "\n",
    "# Guardrails env vars\n",
    "os.environ[\"GUARDRAILS_SERVICE_URL\"] = GUARDRAILS_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "363f0c9d-79d1-4fdd-a265-19b46ffaa386",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fp = f\"{CUSTOMIZATION_DATA_ROOT}/training.jsonl\"\n",
    "assert os.path.exists(train_fp), f\"The training data at '{train_fp}' does not exist. Please ensure that the data was prepared successfully.\"\n",
    "\n",
    "val_fp = f\"{VALIDATION_DATA_ROOT}/validation.jsonl\"\n",
    "assert os.path.exists(val_fp), f\"The validation data at '{val_fp}' does not exist. Please ensure that the data was prepared successfully.\"\n",
    "\n",
    "test_fp = f\"{EVALUATION_DATA_ROOT}/xlam-test-single.jsonl\"\n",
    "assert os.path.exists(test_fp), f\"The test data at '{test_fp}' does not exist. Please ensure that the data was prepared successfully.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b242c1f9-33d8-486d-884a-48682b2f0618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_namespaces(entity_host, ds_host, namespace):\n",
    "    # Create namespace in Entity Store\n",
    "    entity_store_url = f\"{entity_host}/v1/namespaces\"\n",
    "    resp = requests.post(entity_store_url, json={\"id\": namespace})\n",
    "    assert resp.status_code in (200, 201, 409, 422), \\\n",
    "        f\"Unexpected response from Entity Store during namespace creation: {resp.status_code}\"\n",
    "    print(resp)\n",
    "\n",
    "    # Create namespace in Data Store\n",
    "    nds_url = f\"{ds_host}/v1/datastore/namespaces\"\n",
    "    resp = requests.post(nds_url, data={\"namespace\": namespace})\n",
    "    assert resp.status_code in (200, 201, 409, 422), \\\n",
    "        f\"Unexpected response from Data Store during namespace creation: {resp.status_code}\"\n",
    "    print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76be5bd6-7a1c-4f6e-8491-cdc629805b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<Response [201]>\n"
     ]
    }
   ],
   "source": [
    "create_namespaces(entity_host=ENTITY_STORE_URL, ds_host=DATA_STORE_URL, namespace=NMS_NAMESPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "270a26cb-2f79-423f-af7e-27e289d342d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Store Status Code: 201\n",
      "Response JSON: {\n",
      "  \"namespace\": \"xlam-tutorial-ns\",\n",
      "  \"created_at\": \"2025-11-06T21:21:20Z\",\n",
      "  \"updated_at\": \"2025-11-06T21:21:20Z\"\n",
      "}\n",
      "Entity Store Status Code: 200\n",
      "Response JSON: {\n",
      "  \"id\": \"xlam-tutorial-ns\",\n",
      "  \"created_at\": \"2025-11-06T21:21:20.118800\",\n",
      "  \"updated_at\": \"2025-11-06T21:21:20.118803\",\n",
      "  \"description\": null,\n",
      "  \"project\": null,\n",
      "  \"custom_fields\": {},\n",
      "  \"ownership\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "res = requests.get(f\"{DATA_STORE_URL}/v1/datastore/namespaces/{NMS_NAMESPACE}\")\n",
    "print(f\"Data Store Status Code: {res.status_code}\\nResponse JSON: {json.dumps(res.json(), indent=2)}\")\n",
    "\n",
    "# Verify Namespace in Entity Store\n",
    "res = requests.get(f\"{ENTITY_STORE_URL}/v1/namespaces/{NMS_NAMESPACE}\")\n",
    "print(f\"Entity Store Status Code: {res.status_code}\\nResponse JSON: {json.dumps(res.json(), indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a3ac60c-1ab8-4068-a48a-4fc2a75dc417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlam-tutorial-ns/xlam-ft-dataset\n"
     ]
    }
   ],
   "source": [
    "repo_id = f\"{NMS_NAMESPACE}/{DATASET_NAME}\"\n",
    "print(repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fce450ea-7025-452f-af92-0d499100749a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepoUrl('datasets/xlam-tutorial-ns/xlam-ft-dataset', endpoint='http://nemodatastore-sample.hacohen-nemo.svc.cluster.local:8000/v1/hf', repo_type='dataset', repo_id='xlam-tutorial-ns/xlam-ft-dataset')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "hf_api = HfApi(endpoint=f\"{DATA_STORE_URL}/v1/hf\", token=\"\")\n",
    "\n",
    "# Create repo\n",
    "hf_api.create_repo(\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4831f26a-a425-46f2-8062-803943d545bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training.jsonl: 100%|██████████| 6.06M/6.06M [00:00<00:00, 412MB/s]\n",
      "validation.jsonl: 100%|██████████| 1.30M/1.30M [00:00<00:00, 202MB/s]\n",
      "xlam-test-single.jsonl: 100%|██████████| 1.19M/1.19M [00:00<00:00, 199MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='', commit_message='Upload testing/xlam-test-single.jsonl with huggingface_hub', commit_description='', oid='283e31d1122a0abeca2ed0e7c1ad95166177b97e', pr_url=None, repo_url=RepoUrl('', endpoint='https://huggingface.co', repo_type='model', repo_id=''), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_api.upload_file(path_or_fileobj=train_fp,\n",
    "    path_in_repo=\"training/training.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")\n",
    "\n",
    "hf_api.upload_file(path_or_fileobj=val_fp,\n",
    "    path_in_repo=\"validation/validation.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")\n",
    "\n",
    "hf_api.upload_file(path_or_fileobj=test_fp,\n",
    "    path_in_repo=\"testing/xlam-test-single.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d2b74b-4c1f-46d5-b9f4-85afe9388c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
