{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94783c11-9f06-4785-8b54-8d309b7bbf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import random\n",
    "from time import sleep, time\n",
    "from openai import OpenAI\n",
    "import asyncio\n",
    "\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a26df36-6d90-4631-bbe7-a97225d3a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NVIDIA_DATASET_NAMESPACE\"] = NMS_NAMESPACE\n",
    "os.environ[\"NVIDIA_PROJECT_ID\"] = PROJECT_ID\n",
    "\n",
    "## Inference env vars\n",
    "os.environ[\"NVIDIA_BASE_URL\"] = NIM_URL\n",
    "\n",
    "# Data Store env vars\n",
    "os.environ[\"NVIDIA_DATASETS_URL\"] = ENTITY_STORE_URL\n",
    "\n",
    "## Customizer env vars\n",
    "os.environ[\"NVIDIA_CUSTOMIZER_URL\"] = CUSTOMIZER_URL\n",
    "os.environ[\"NVIDIA_OUTPUT_MODEL_DIR\"] = CUSTOMIZED_MODEL_DIR\n",
    "\n",
    "# Evaluator env vars\n",
    "os.environ[\"NVIDIA_EVALUATOR_URL\"] = EVALUATOR_URL\n",
    "\n",
    "# Guardrails env vars\n",
    "os.environ[\"GUARDRAILS_SERVICE_URL\"] = GUARDRAILS_URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d60defd-6835-477a-9d79-490b083d47f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OTEL_EXPORTER_OTLP_ENDPOINT is not set, skipping telemetry\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Using config <span style=\"color: #000080; text-decoration-color: #000080\">nvidia</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Using config \u001b[34mnvidia\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">apis:\n",
       "- agents\n",
       "- datasetio\n",
       "- eval\n",
       "- files\n",
       "- inference\n",
       "- post_training\n",
       "- safety\n",
       "- scoring\n",
       "- tool_runtime\n",
       "- vector_io\n",
       "container_image: null\n",
       "external_apis_dir: null\n",
       "external_providers_dir: null\n",
       "image_name: nvidia\n",
       "logging: null\n",
       "providers:\n",
       "  agents:\n",
       "  - config:\n",
       "      persistence:\n",
       "        agent_state:\n",
       "          backend: kv_default\n",
       "          namespace: agents\n",
       "        responses:\n",
       "          backend: sql_default\n",
       "          max_write_queue_size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10000</span>\n",
       "          num_writers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>\n",
       "          table_name: responses\n",
       "    module: null\n",
       "    provider_id: meta-reference\n",
       "    provider_type: inline::meta-reference\n",
       "  datasetio:\n",
       "  - config:\n",
       "      api_key: <span style=\"color: #008000; text-decoration-color: #008000\">'********'</span>\n",
       "      dataset_namespace: xlam-tutorial-ns\n",
       "      datasets_url: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">http://nemoentitystore-sample.hacohen-nemo.svc.cluster.local:8000</span>\n",
       "      project_id: test-project\n",
       "    module: null\n",
       "    provider_id: nvidia\n",
       "    provider_type: remote::nvidia\n",
       "  eval:\n",
       "  - config:\n",
       "      evaluator_url: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">http://nemoevaluator-sample.hacohen-nemo.svc.cluster.local:8000</span>\n",
       "    module: null\n",
       "    provider_id: nvidia\n",
       "    provider_type: remote::nvidia\n",
       "  files:\n",
       "  - config:\n",
       "      metadata_store:\n",
       "        backend: sql_default\n",
       "        table_name: files_metadata\n",
       "      storage_dir: <span style=\"color: #800080; text-decoration-color: #800080\">/opt/app-root/src/.llama/distributions/nvidia/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">files</span>\n",
       "    module: null\n",
       "    provider_id: meta-reference-files\n",
       "    provider_type: inline::localfs\n",
       "  inference:\n",
       "  - config:\n",
       "      api_key: <span style=\"color: #008000; text-decoration-color: #008000\">'********'</span>\n",
       "      append_api_version: true\n",
       "      url: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">http://meta-llama3-1b-instruct.hacohen-nemo.svc.cluster.local:8000</span>\n",
       "    module: null\n",
       "    provider_id: nvidia\n",
       "    provider_type: remote::nvidia\n",
       "  post_training:\n",
       "  - config:\n",
       "      api_key: <span style=\"color: #008000; text-decoration-color: #008000\">'********'</span>\n",
       "      customizer_url: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">http://nemocustomizer-sample.hacohen-nemo.svc.cluster.local:8000</span>\n",
       "      dataset_namespace: xlam-tutorial-ns\n",
       "      project_id: test-project\n",
       "    module: null\n",
       "    provider_id: nvidia\n",
       "    provider_type: remote::nvidia\n",
       "  safety:\n",
       "  - config:\n",
       "      config_id: self-check\n",
       "      guardrails_service_url: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">http://nemoguardrails-sample.hacohen-nemo.svc.cluster.local:8000</span>\n",
       "    module: null\n",
       "    provider_id: nvidia\n",
       "    provider_type: remote::nvidia\n",
       "  scoring:\n",
       "  - config: <span style=\"font-weight: bold\">{}</span>\n",
       "    module: null\n",
       "    provider_id: basic\n",
       "    provider_type: inlin<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e::ba</span>sic\n",
       "  tool_runtime:\n",
       "  - config: <span style=\"font-weight: bold\">{}</span>\n",
       "    module: null\n",
       "    provider_id: rag-runtime\n",
       "    provider_type: inline::rag-runtime\n",
       "  vector_io:\n",
       "  - config:\n",
       "      persistence:\n",
       "        backend: kv_default\n",
       "        namespace: vector_io::faiss\n",
       "    module: null\n",
       "    provider_id: faiss\n",
       "    provider_type: inlin<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e::fa</span>iss\n",
       "registered_resources:\n",
       "  benchmarks: <span style=\"font-weight: bold\">[]</span>\n",
       "  datasets: <span style=\"font-weight: bold\">[]</span>\n",
       "  models: <span style=\"font-weight: bold\">[]</span>\n",
       "  scoring_fns: <span style=\"font-weight: bold\">[]</span>\n",
       "  shields: <span style=\"font-weight: bold\">[]</span>\n",
       "  tool_groups:\n",
       "  - args: null\n",
       "    mcp_endpoint: null\n",
       "    provider_id: rag-runtime\n",
       "    toolgroup_id: builtin::rag\n",
       "  vector_stores: <span style=\"font-weight: bold\">[]</span>\n",
       "server:\n",
       "  auth: null\n",
       "  cors: null\n",
       "  host: null\n",
       "  port: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8321</span>\n",
       "  quota: null\n",
       "  tls_cafile: null\n",
       "  tls_certfile: null\n",
       "  tls_keyfile: null\n",
       "  workers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "storage:\n",
       "  backends:\n",
       "    kv_default:\n",
       "      db_path: <span style=\"color: #800080; text-decoration-color: #800080\">/opt/app-root/src/.llama/distributions/nvidia/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">kvstore.db</span>\n",
       "      namespace: null\n",
       "      type: !!python/object/apply:llama_stack.core.storage.datatypes.StorageBackendType\n",
       "      - kv_sqlite\n",
       "    sql_default:\n",
       "      db_path: <span style=\"color: #800080; text-decoration-color: #800080\">/opt/app-root/src/.llama/distributions/nvidia/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">sql_store.db</span>\n",
       "      type: !!python/object/apply:llama_stack.core.storage.datatypes.StorageBackendType\n",
       "      - sql_sqlite\n",
       "  stores:\n",
       "    conversations:\n",
       "      backend: sql_default\n",
       "      table_name: openai_conversations\n",
       "    inference:\n",
       "      backend: sql_default\n",
       "      max_write_queue_size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10000</span>\n",
       "      num_writers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>\n",
       "      table_name: inference_store\n",
       "    metadata:\n",
       "      backend: kv_default\n",
       "      namespace: registry\n",
       "    responses: null\n",
       "telemetry:\n",
       "  enabled: true\n",
       "vector_stores: null\n",
       "version: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "apis:\n",
       "- agents\n",
       "- datasetio\n",
       "- eval\n",
       "- files\n",
       "- inference\n",
       "- post_training\n",
       "- safety\n",
       "- scoring\n",
       "- tool_runtime\n",
       "- vector_io\n",
       "container_image: null\n",
       "external_apis_dir: null\n",
       "external_providers_dir: null\n",
       "image_name: nvidia\n",
       "logging: null\n",
       "providers:\n",
       "  agents:\n",
       "  - config:\n",
       "      persistence:\n",
       "        agent_state:\n",
       "          backend: kv_default\n",
       "          namespace: agents\n",
       "        responses:\n",
       "          backend: sql_default\n",
       "          max_write_queue_size: \u001b[1;36m10000\u001b[0m\n",
       "          num_writers: \u001b[1;36m4\u001b[0m\n",
       "          table_name: responses\n",
       "    module: null\n",
       "    provider_id: meta-reference\n",
       "    provider_type: inline::meta-reference\n",
       "  datasetio:\n",
       "  - config:\n",
       "      api_key: \u001b[32m'********'\u001b[0m\n",
       "      dataset_namespace: xlam-tutorial-ns\n",
       "      datasets_url: \u001b[4;94mhttp://nemoentitystore-sample.hacohen-nemo.svc.cluster.local:8000\u001b[0m\n",
       "      project_id: test-project\n",
       "    module: null\n",
       "    provider_id: nvidia\n",
       "    provider_type: remote::nvidia\n",
       "  eval:\n",
       "  - config:\n",
       "      evaluator_url: \u001b[4;94mhttp://nemoevaluator-sample.hacohen-nemo.svc.cluster.local:8000\u001b[0m\n",
       "    module: null\n",
       "    provider_id: nvidia\n",
       "    provider_type: remote::nvidia\n",
       "  files:\n",
       "  - config:\n",
       "      metadata_store:\n",
       "        backend: sql_default\n",
       "        table_name: files_metadata\n",
       "      storage_dir: \u001b[35m/opt/app-root/src/.llama/distributions/nvidia/\u001b[0m\u001b[95mfiles\u001b[0m\n",
       "    module: null\n",
       "    provider_id: meta-reference-files\n",
       "    provider_type: inline::localfs\n",
       "  inference:\n",
       "  - config:\n",
       "      api_key: \u001b[32m'********'\u001b[0m\n",
       "      append_api_version: true\n",
       "      url: \u001b[4;94mhttp://meta-llama3-1b-instruct.hacohen-nemo.svc.cluster.local:8000\u001b[0m\n",
       "    module: null\n",
       "    provider_id: nvidia\n",
       "    provider_type: remote::nvidia\n",
       "  post_training:\n",
       "  - config:\n",
       "      api_key: \u001b[32m'********'\u001b[0m\n",
       "      customizer_url: \u001b[4;94mhttp://nemocustomizer-sample.hacohen-nemo.svc.cluster.local:8000\u001b[0m\n",
       "      dataset_namespace: xlam-tutorial-ns\n",
       "      project_id: test-project\n",
       "    module: null\n",
       "    provider_id: nvidia\n",
       "    provider_type: remote::nvidia\n",
       "  safety:\n",
       "  - config:\n",
       "      config_id: self-check\n",
       "      guardrails_service_url: \u001b[4;94mhttp://nemoguardrails-sample.hacohen-nemo.svc.cluster.local:8000\u001b[0m\n",
       "    module: null\n",
       "    provider_id: nvidia\n",
       "    provider_type: remote::nvidia\n",
       "  scoring:\n",
       "  - config: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "    module: null\n",
       "    provider_id: basic\n",
       "    provider_type: inlin\u001b[1;92me::ba\u001b[0msic\n",
       "  tool_runtime:\n",
       "  - config: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "    module: null\n",
       "    provider_id: rag-runtime\n",
       "    provider_type: inline::rag-runtime\n",
       "  vector_io:\n",
       "  - config:\n",
       "      persistence:\n",
       "        backend: kv_default\n",
       "        namespace: vector_io::faiss\n",
       "    module: null\n",
       "    provider_id: faiss\n",
       "    provider_type: inlin\u001b[1;92me::fa\u001b[0miss\n",
       "registered_resources:\n",
       "  benchmarks: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "  datasets: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "  models: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "  scoring_fns: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "  shields: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "  tool_groups:\n",
       "  - args: null\n",
       "    mcp_endpoint: null\n",
       "    provider_id: rag-runtime\n",
       "    toolgroup_id: builtin::rag\n",
       "  vector_stores: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "server:\n",
       "  auth: null\n",
       "  cors: null\n",
       "  host: null\n",
       "  port: \u001b[1;36m8321\u001b[0m\n",
       "  quota: null\n",
       "  tls_cafile: null\n",
       "  tls_certfile: null\n",
       "  tls_keyfile: null\n",
       "  workers: \u001b[1;36m1\u001b[0m\n",
       "storage:\n",
       "  backends:\n",
       "    kv_default:\n",
       "      db_path: \u001b[35m/opt/app-root/src/.llama/distributions/nvidia/\u001b[0m\u001b[95mkvstore.db\u001b[0m\n",
       "      namespace: null\n",
       "      type: !!python/object/apply:llama_stack.core.storage.datatypes.StorageBackendType\n",
       "      - kv_sqlite\n",
       "    sql_default:\n",
       "      db_path: \u001b[35m/opt/app-root/src/.llama/distributions/nvidia/\u001b[0m\u001b[95msql_store.db\u001b[0m\n",
       "      type: !!python/object/apply:llama_stack.core.storage.datatypes.StorageBackendType\n",
       "      - sql_sqlite\n",
       "  stores:\n",
       "    conversations:\n",
       "      backend: sql_default\n",
       "      table_name: openai_conversations\n",
       "    inference:\n",
       "      backend: sql_default\n",
       "      max_write_queue_size: \u001b[1;36m10000\u001b[0m\n",
       "      num_writers: \u001b[1;36m4\u001b[0m\n",
       "      table_name: inference_store\n",
       "    metadata:\n",
       "      backend: kv_default\n",
       "      namespace: registry\n",
       "    responses: null\n",
       "telemetry:\n",
       "  enabled: true\n",
       "vector_stores: null\n",
       "version: \u001b[1;36m2\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_stack.core.library_client import LlamaStackAsLibraryClient\n",
    "\n",
    "client = LlamaStackAsLibraryClient(\"nvidia\")\n",
    "client.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6fb75ce-6ccd-4305-bf13-583620f262d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_stack.apis.common.job_types import JobStatus\n",
    "from llama_stack.core.datatypes import Api\n",
    "\n",
    "async def wait_eval_job(benchmark_id: str, job_id: str, polling_interval: int = 10, timeout: int = 6000):\n",
    "    start_time = time()\n",
    "    \n",
    "    # Access eval through impls\n",
    "    eval_impl = client.async_client.impls[Api.eval]\n",
    "    \n",
    "    job_status = await eval_impl.job_status(benchmark_id=benchmark_id, job_id=job_id)\n",
    "\n",
    "    print(f\"Waiting for Evaluation job {job_id} to finish.\")\n",
    "    print(f\"Job status: {job_status.status} after {time() - start_time} seconds.\")\n",
    "\n",
    "    while job_status.status in [JobStatus.scheduled, JobStatus.in_progress]:\n",
    "        await asyncio.sleep(polling_interval)\n",
    "        job_status = await eval_impl.job_status(benchmark_id=benchmark_id, job_id=job_id)\n",
    "\n",
    "        print(f\"Job status: {job_status.status} after {time() - start_time} seconds.\")\n",
    "\n",
    "        if time() - start_time > timeout:\n",
    "            raise RuntimeError(f\"Evaluation Job {job_id} took more than {timeout} seconds.\")\n",
    "\n",
    "    return job_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "370d6200-197c-4269-a00d-2c842020b360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Store endpoint: http://nemodatastore-sample.hacohen-nemo.svc.cluster.local:8000\n",
      "Entity Store endpoint: http://nemoentitystore-sample.hacohen-nemo.svc.cluster.local:8000\n",
      "Customizer endpoint: http://nemocustomizer-sample.hacohen-nemo.svc.cluster.local:8000\n",
      "Evaluator endpoint: http://nemoevaluator-sample.hacohen-nemo.svc.cluster.local:8000\n",
      "NIM endpoint: http://meta-llama3-1b-instruct.hacohen-nemo.svc.cluster.local:8000\n",
      "Namespace: xlam-tutorial-ns\n",
      "Base Model: meta/llama-3.2-1b-instruct\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data Store endpoint: {DATA_STORE_URL}\")\n",
    "print(f\"Entity Store endpoint: {ENTITY_STORE_URL}\")\n",
    "print(f\"Customizer endpoint: {CUSTOMIZER_URL}\")\n",
    "print(f\"Evaluator endpoint: {EVALUATOR_URL}\")\n",
    "print(f\"NIM endpoint: {NIM_URL}\")\n",
    "print(f\"Namespace: {NMS_NAMESPACE}\")\n",
    "print(f\"Base Model: {BASE_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e99a72c-3e01-4d69-bf93-2dd2f92405ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOMIZED_MODEL = \"nvidia-tool-calling-tutorial/test-llama-stack@v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff0619ee-18ea-4203-b67d-4d856ee50d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = client.models.list()\n",
    "model_ids = [model.identifier for model in models]\n",
    "\n",
    "assert f\"nvidia/{CUSTOMIZED_MODEL}\" in model_ids, \\\n",
    "    f\"Model {CUSTOMIZED_MODEL} not registered\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "673aab19-c14d-4411-a6a1-b4e5835b924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(f\"{NIM_URL}/v1/models\")\n",
    "\n",
    "models = resp.json().get(\"data\", [])\n",
    "model_names = [model[\"id\"] for model in models]\n",
    "\n",
    "assert CUSTOMIZED_MODEL in model_names, \\\n",
    "    f\"Model {CUSTOMIZED_MODEL} not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da8741fc-7378-466c-8c20-d3592487b353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['meta/llama-3.2-1b-instruct',\n",
       "  'nvidia-tool-calling-tutorial/test-llama-stack@v1'],\n",
       " ['nvidia/meta/llama-3.2-1b-instruct',\n",
       "  'nvidia/nvidia-tool-calling-tutorial/test-llama-stack@v1'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names, model_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f74cb326-17ed-4b85-bb28-677a90863b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlam-tutorial-ns/xlam-ft-dataset\n"
     ]
    }
   ],
   "source": [
    "repo_id = f\"{NMS_NAMESPACE}/{DATASET_NAME}\"\n",
    "print(repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e85fd85-c91a-4a47-81a9-072a1c846def",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = client.datasets.list()\n",
    "dataset_ids = [dataset.identifier for dataset in datasets]\n",
    "assert DATASET_NAME in dataset_ids, \\\n",
    "    f\"Dataset {DATASET_NAME} not registered\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a4816ae-336b-4871-b6c8-a732450f10e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xlam-ft-dataset']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2087354-f185-4b1d-8bcf-a199f4659621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files URL: hf://datasets/xlam-tutorial-ns/xlam-ft-dataset\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(url=f\"{ENTITY_STORE_URL}/v1/datasets/{repo_id}\")\n",
    "assert response.status_code in (200, 201), f\"Status Code {response.status_code} Failed to fetch dataset {response.text}\"\n",
    "\n",
    "print(\"Files URL:\", response.json()[\"files_url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbd8a183-d692-47d7-95c5-9413aa59c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_id = \"simple-tool-calling-1\"\n",
    "simple_tool_calling_eval_config = {\n",
    "    \"type\": \"custom\",\n",
    "    \"tasks\": {\n",
    "        \"custom-tool-calling\": {\n",
    "            \"type\": \"chat-completion\",\n",
    "            \"dataset\": {\n",
    "                \"files_url\": f\"hf://datasets/{NMS_NAMESPACE}/{DATASET_NAME}/testing/xlam-test-single.jsonl\",\n",
    "                \"limit\": 50\n",
    "            },\n",
    "            \"params\": {\n",
    "                \"template\": {\n",
    "                    \"messages\": \"{{ item.messages | tojson}}\",\n",
    "                    \"tools\": \"{{ item.tools | tojson }}\",\n",
    "                    \"tool_choice\": \"auto\"\n",
    "                }\n",
    "            },\n",
    "            \"metrics\": {\n",
    "                \"tool-calling-accuracy\": {\n",
    "                    \"type\": \"tool-calling\",\n",
    "                    \"params\": {\"tool_calls_ground_truth\": \"{{ item.tool_calls | tojson }}\"}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "784ba7f9-3009-4653-99ee-ecb88578aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.benchmarks.register(\n",
    "    benchmark_id=benchmark_id,\n",
    "    dataset_id=repo_id,\n",
    "    scoring_functions=[],\n",
    "    metadata=simple_tool_calling_eval_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59823075-26f2-443f-8843-93cb09df75c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Registered model in 'meta' namespace!\n",
      "{\n",
      "  \"created_at\": \"2025-11-06T22:30:23.000366\",\n",
      "  \"updated_at\": \"2025-11-06T22:30:23.000368\",\n",
      "  \"name\": \"llama-3.2-1b-instruct\",\n",
      "  \"namespace\": \"meta\",\n",
      "  \"description\": \"Base Llama 3.2 1B Instruct model\",\n",
      "  \"spec\": null,\n",
      "  \"artifact\": null,\n",
      "  \"base_model\": null,\n",
      "  \"api_endpoint\": null,\n",
      "  \"peft\": null,\n",
      "  \"prompt\": null,\n",
      "  \"guardrails\": null,\n",
      "  \"schema_version\": \"1.0\",\n",
      "  \"project\": null,\n",
      "  \"custom_fields\": {},\n",
      "  \"ownership\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Try registering with colon instead of slash (meta:llama-3.2-1b-instruct)\n",
    "# Or see if we can create an alias\n",
    "model_payload = {\n",
    "    \"namespace\": \"meta\",  # Use meta as the namespace\n",
    "    \"name\": \"llama-3.2-1b-instruct\",\n",
    "    \"description\": \"Base Llama 3.2 1B Instruct model\",\n",
    "    \"type\": \"llm\",\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(\n",
    "        f\"{ENTITY_STORE_URL}/v1/models\",\n",
    "        json=model_payload\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    print(\"✓ Registered model in 'meta' namespace!\")\n",
    "    print(json.dumps(response.json(), indent=2))\n",
    "except requests.HTTPError as e:\n",
    "    print(f\"Status: {e.response.status_code}\")\n",
    "    print(f\"Response: {e.response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24f48ecd-b0e6-4371-899e-9d7b820f095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "\n",
    "# # Delete the existing model (already done, but just in case)\n",
    "# try:\n",
    "#     response = requests.delete(f\"{ENTITY_STORE_URL}/v1/models/meta/llama-3.2-1b-instruct\")\n",
    "#     print(f\"Delete status: {response.status_code}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Delete error (ok if 404): {e}\")\n",
    "\n",
    "# # Create with the API endpoint - let's see the exact error\n",
    "# model_payload = {\n",
    "#     \"namespace\": \"meta\",\n",
    "#     \"name\": \"llama-3.2-1b-instruct\",\n",
    "#     \"description\": \"Base Llama 3.2 1B Instruct model\",\n",
    "#     \"type\": \"llm\",\n",
    "#     \"api_endpoint\": NIM_URL  # Add the NIM endpoint\n",
    "# }\n",
    "\n",
    "# print(f\"\\nPayload:\")\n",
    "# print(json.dumps(model_payload, indent=2))\n",
    "# print(f\"\\nNIM_URL value: {NIM_URL}\")\n",
    "\n",
    "# try:\n",
    "#     response = requests.post(\n",
    "#         f\"{ENTITY_STORE_URL}/v1/models\",\n",
    "#         json=model_payload\n",
    "#     )\n",
    "#     response.raise_for_status()\n",
    "#     print(\"✓ Created model with API endpoint!\")\n",
    "#     print(json.dumps(response.json(), indent=2))\n",
    "# except requests.HTTPError as e:\n",
    "#     print(f\"✗ Status: {e.response.status_code}\")\n",
    "#     print(f\"Error details: {e.response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8115509-a179-4046-8179-b1892599938e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created evaluation job: eval-5qTD3dDTcRfHKdbow1m7GX\n"
     ]
    }
   ],
   "source": [
    "from llama_stack.core.datatypes import Api\n",
    "from llama_stack.apis.eval import BenchmarkConfig, EvalCandidate\n",
    "\n",
    "# Access eval through impls\n",
    "eval_impl = client.async_client.impls[Api.eval]\n",
    "\n",
    "# Create the benchmark config using proper data types\n",
    "from llama_stack.apis.eval import ModelCandidate, SamplingParams\n",
    "\n",
    "benchmark_config = BenchmarkConfig(\n",
    "    eval_candidate=ModelCandidate(\n",
    "        type=\"model\",\n",
    "        model=BASE_MODEL,\n",
    "        sampling_params=SamplingParams()\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create evaluation job\n",
    "response = await eval_impl.run_eval(\n",
    "    benchmark_id=benchmark_id,\n",
    "    benchmark_config=benchmark_config\n",
    ")\n",
    "\n",
    "job_id = response.job_id\n",
    "print(f\"Created evaluation job: {job_id}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "136cfa9c-2693-4c42-967e-3399aa087c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Evaluation job eval-5qTD3dDTcRfHKdbow1m7GX to finish.\n",
      "Job status: JobStatus.in_progress after 0.009132623672485352 seconds.\n",
      "Job status: JobStatus.in_progress after 5.022626161575317 seconds.\n",
      "Job status: JobStatus.in_progress after 10.036325931549072 seconds.\n",
      "Job status: JobStatus.in_progress after 15.051011562347412 seconds.\n",
      "Job status: JobStatus.in_progress after 20.0600528717041 seconds.\n",
      "Job status: JobStatus.completed after 25.07395601272583 seconds.\n"
     ]
    }
   ],
   "source": [
    "job = await wait_eval_job(benchmark_id=benchmark_id, job_id=job_id, polling_interval=5, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c25e6950-ac12-4fcd-97a6-00558bc38fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: completed\n",
      "\n",
      "Status details:\n",
      "{\n",
      "  \"message\": \"Job completed successfully.\",\n",
      "  \"task_status\": {\n",
      "    \"custom-tool-calling\": \"completed\"\n",
      "  },\n",
      "  \"progress\": 100.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Get the full job details to see the error\n",
    "response = requests.get(f\"{EVALUATOR_URL}/v1/evaluation/jobs/{job_id}\")\n",
    "response.raise_for_status()\n",
    "job_details = response.json()\n",
    "\n",
    "print(\"Job status:\", job_details.get(\"status\"))\n",
    "print(\"\\nStatus details:\")\n",
    "if \"status_details\" in job_details:\n",
    "    print(json.dumps(job_details[\"status_details\"], indent=2))\n",
    "    \n",
    "# print(\"\\nFull job details:\")\n",
    "# print(json.dumps(job_details, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6caea215-1a0e-4739-8ff2-1a83f111a637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available client attributes:\n",
      "['alpha', 'api_key', 'async_client', 'auth_headers', 'base_url', 'benchmarks', 'chat', 'close', 'completions', 'conversations', 'copy', 'custom_auth', 'datasets', 'default_headers', 'default_query', 'delete', 'embeddings', 'files', 'get', 'get_api_list', 'initialize', 'inspect', 'is_closed', 'loop', 'max_retries', 'models', 'moderations', 'patch', 'platform_headers', 'post', 'provider_data', 'providers', 'put', 'qs', 'request', 'responses', 'routes', 'safety', 'scoring', 'scoring_functions', 'shields', 'synthetic_data_generation', 'telemetry', 'timeout', 'tool_runtime', 'toolgroups', 'tools', 'user_agent', 'vector_io', 'vector_stores', 'with_options', 'with_raw_response', 'with_streaming_response']\n",
      "Client does not have eval/evaluations/evaluation attributes\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "# import json\n",
    "\n",
    "# # List all models in the Entity Store\n",
    "# response = requests.get(f\"{ENTITY_STORE_URL}/v1/models\")\n",
    "# response.raise_for_status()\n",
    "# models = response.json()\n",
    "\n",
    "# print(\"Models in Entity Store:\")\n",
    "# print(json.dumps(models, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdcc1d3b-cfcb-4fa4-b6f2-6b42f4e50653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job results: {\n",
      "  \"generations\": [],\n",
      "  \"scores\": {\n",
      "    \"simple-tool-calling-1\": {\n",
      "      \"score_rows\": [],\n",
      "      \"aggregated_results\": {\n",
      "        \"created_at\": \"2025-11-06T22:33:37.013669\",\n",
      "        \"updated_at\": \"2025-11-06T22:33:37.013670\",\n",
      "        \"id\": \"evaluation_result-25WgaVDdJxCiniWZkT6JHY\",\n",
      "        \"job\": \"eval-5qTD3dDTcRfHKdbow1m7GX\",\n",
      "        \"tasks\": {\n",
      "          \"custom-tool-calling\": {\n",
      "            \"metrics\": {\n",
      "              \"tool-calling-accuracy\": {\n",
      "                \"scores\": {\n",
      "                  \"function_name_accuracy\": {\n",
      "                    \"value\": 0.02,\n",
      "                    \"stats\": {\n",
      "                      \"count\": 50,\n",
      "                      \"sum\": 1.0,\n",
      "                      \"mean\": 0.02\n",
      "                    }\n",
      "                  },\n",
      "                  \"function_name_and_args_accuracy\": {\n",
      "                    \"value\": 0.0,\n",
      "                    \"stats\": {\n",
      "                      \"count\": 50,\n",
      "                      \"sum\": 0.0,\n",
      "                      \"mean\": 0.0\n",
      "                    }\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"groups\": {},\n",
      "        \"namespace\": \"default\",\n",
      "        \"custom_fields\": {}\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from llama_stack.core.datatypes import Api\n",
    "\n",
    "# Access eval through impls\n",
    "eval_impl = client.async_client.impls[Api.eval]\n",
    "\n",
    "# Retrieve job results\n",
    "job_results = await eval_impl.job_result(benchmark_id=benchmark_id, job_id=job_id)\n",
    "print(f\"Job results: {json.dumps(job_results.model_dump(), indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2834a430-b868-46b4-b0d4-c0c75d22d6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model: function_name_accuracy: 0.02\n",
      "Base model: function_name_and_args_accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "aggregated_results = job_results.scores[benchmark_id].aggregated_results\n",
    "base_function_name_accuracy_score = aggregated_results[\"tasks\"][\"custom-tool-calling\"][\"metrics\"][\"tool-calling-accuracy\"][\"scores\"][\"function_name_accuracy\"][\"value\"]\n",
    "base_function_name_and_args_accuracy = aggregated_results[\"tasks\"][\"custom-tool-calling\"][\"metrics\"][\"tool-calling-accuracy\"][\"scores\"][\"function_name_and_args_accuracy\"][\"value\"]\n",
    "\n",
    "print(f\"Base model: function_name_accuracy: {base_function_name_accuracy_score}\")\n",
    "print(f\"Base model: function_name_and_args_accuracy: {base_function_name_and_args_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7607ad7-b97d-421a-a0ef-c5a3a4e34898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created evaluation job: eval-BuCn79PVV4nus5o5icY8Wz\n"
     ]
    }
   ],
   "source": [
    "from llama_stack.core.datatypes import Api\n",
    "from llama_stack.apis.eval import BenchmarkConfig, EvalCandidate\n",
    "\n",
    "# Access eval through impls\n",
    "eval_impl = client.async_client.impls[Api.eval]\n",
    "\n",
    "# Create the benchmark config using proper data types\n",
    "from llama_stack.apis.eval import ModelCandidate, SamplingParams\n",
    "\n",
    "benchmark_config = BenchmarkConfig(\n",
    "    eval_candidate=ModelCandidate(\n",
    "        type=\"model\",\n",
    "        model=CUSTOMIZED_MODEL,\n",
    "        sampling_params=SamplingParams()\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create evaluation job\n",
    "response = await eval_impl.run_eval(\n",
    "    benchmark_id=benchmark_id,\n",
    "    benchmark_config=benchmark_config\n",
    ")\n",
    "\n",
    "job_id = response.job_id\n",
    "print(f\"Created evaluation job: {job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19435e23-ed8e-4ff5-bcb2-8c68ee82972c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Evaluation job eval-BuCn79PVV4nus5o5icY8Wz to finish.\n",
      "Job status: JobStatus.in_progress after 0.04833269119262695 seconds.\n",
      "Job status: JobStatus.in_progress after 5.064541578292847 seconds.\n",
      "Job status: JobStatus.in_progress after 10.078007936477661 seconds.\n",
      "Job status: JobStatus.completed after 15.09185266494751 seconds.\n"
     ]
    }
   ],
   "source": [
    "job = await wait_eval_job(benchmark_id=benchmark_id, job_id=job_id, polling_interval=5, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15416460-f616-463e-8031-7b3b29d1d44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job results: {\n",
      "  \"generations\": [],\n",
      "  \"scores\": {\n",
      "    \"simple-tool-calling-1\": {\n",
      "      \"score_rows\": [],\n",
      "      \"aggregated_results\": {\n",
      "        \"created_at\": \"2025-11-06T22:41:32.282836\",\n",
      "        \"updated_at\": \"2025-11-06T22:41:32.282837\",\n",
      "        \"id\": \"evaluation_result-GojEP63Z9tWMtYHJZJq2vm\",\n",
      "        \"job\": \"eval-BuCn79PVV4nus5o5icY8Wz\",\n",
      "        \"tasks\": {\n",
      "          \"custom-tool-calling\": {\n",
      "            \"metrics\": {\n",
      "              \"tool-calling-accuracy\": {\n",
      "                \"scores\": {\n",
      "                  \"function_name_accuracy\": {\n",
      "                    \"value\": 0.9,\n",
      "                    \"stats\": {\n",
      "                      \"count\": 50,\n",
      "                      \"sum\": 45.0,\n",
      "                      \"mean\": 0.9\n",
      "                    }\n",
      "                  },\n",
      "                  \"function_name_and_args_accuracy\": {\n",
      "                    \"value\": 0.68,\n",
      "                    \"stats\": {\n",
      "                      \"count\": 50,\n",
      "                      \"sum\": 34.0,\n",
      "                      \"mean\": 0.68\n",
      "                    }\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"groups\": {},\n",
      "        \"namespace\": \"default\",\n",
      "        \"custom_fields\": {}\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from llama_stack.core.datatypes import Api\n",
    "\n",
    "# Access eval through impls\n",
    "eval_impl = client.async_client.impls[Api.eval]\n",
    "\n",
    "# Retrieve job results\n",
    "job_results = await eval_impl.job_result(benchmark_id=benchmark_id, job_id=job_id)\n",
    "print(f\"Job results: {json.dumps(job_results.model_dump(), indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "968db57e-01e7-450f-b6e2-812310eb4bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom model: function_name_accuracy: 0.9\n",
      "Custom model: function_name_and_args_accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "aggregated_results_custom = job_results.scores[benchmark_id].aggregated_results\n",
    "custom_function_name_accuracy_score = aggregated_results_custom[\"tasks\"][\"custom-tool-calling\"][\"metrics\"][\"tool-calling-accuracy\"][\"scores\"][\"function_name_accuracy\"][\"value\"]\n",
    "custom_function_name_and_args_accuracy = aggregated_results_custom[\"tasks\"][\"custom-tool-calling\"][\"metrics\"][\"tool-calling-accuracy\"][\"scores\"][\"function_name_and_args_accuracy\"][\"value\"]\n",
    "\n",
    "print(f\"Custom model: function_name_accuracy: {custom_function_name_accuracy_score}\")\n",
    "print(f\"Custom model: function_name_and_args_accuracy: {custom_function_name_and_args_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac36b2e-bdf9-455d-a532-dc275cf6f7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
