{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93308668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (0.36.0)\n",
      "Requirement already satisfied: transformers>=4.36.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (4.57.1)\n",
      "Requirement already satisfied: peft in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (0.17.1)\n",
      "Requirement already satisfied: datasets in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (4.4.1)\n",
      "Requirement already satisfied: trl in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (0.25.0)\n",
      "Requirement already satisfied: jsonschema in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (4.25.1)\n",
      "Requirement already satisfied: litellm in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (1.79.3)\n",
      "Requirement already satisfied: jinja2>=3.1.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (3.1.6)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (2.9.0)\n",
      "Requirement already satisfied: openai in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (2.7.2)\n",
      "Requirement already satisfied: jupyterlab in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (4.4.10)\n",
      "Requirement already satisfied: requests in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (2.32.5)\n",
      "Requirement already satisfied: filelock in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from huggingface_hub) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from huggingface_hub) (2025.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from huggingface_hub) (6.0.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from huggingface_hub) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from transformers>=4.36.0) (2.3.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from transformers>=4.36.0) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from transformers>=4.36.0) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from transformers>=4.36.0) (0.6.2)\n",
      "Requirement already satisfied: psutil in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from peft) (7.1.3)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from peft) (1.11.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jsonschema) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jsonschema) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jsonschema) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jsonschema) (0.28.0)\n",
      "Requirement already satisfied: click in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from litellm) (8.3.0)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from litellm) (0.14.0)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from litellm) (8.7.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from litellm) (2.12.4)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from litellm) (1.2.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from litellm) (0.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jinja2>=3.1.0) (3.0.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.0->litellm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.0->litellm) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.0->litellm) (0.4.2)\n",
      "Requirement already satisfied: setuptools in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from torch>=2.0.0) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from torch>=2.0.0) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from torch>=2.0.0) (3.5)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyterlab) (2.0.5)\n",
      "Requirement already satisfied: ipykernel!=6.30.0,>=6.5.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyterlab) (7.1.0)\n",
      "Requirement already satisfied: jupyter-core in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyterlab) (5.9.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyterlab) (2.3.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyterlab) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyterlab) (2.28.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyterlab) (0.2.4)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyterlab) (6.5.2)\n",
      "Requirement already satisfied: traitlets in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyterlab) (5.14.3)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (25.1.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (8.6.3)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.23.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (27.1.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.9.0)\n",
      "Requirement already satisfied: babel>=2.10 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.12.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (25.1.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from importlib-metadata>=6.8.0->litellm) (3.23.0)\n",
      "Requirement already satisfied: appnope>=0.1.2 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (1.8.17)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (9.7.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (1.6.0)\n",
      "Requirement already satisfied: decorator>=4.3.2 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jedi>=0.18.1->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.8.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyter-core->jupyterlab) (4.5.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (4.0.0)\n",
      "Requirement already satisfied: rfc3339-validator in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
      "Requirement already satisfied: fqdn in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.1.0)\n",
      "Requirement already satisfied: uri-template in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (25.10.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.14.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (6.3.0)\n",
      "Requirement already satisfied: defusedxml in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: webencodings in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.21.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.0)\n",
      "Requirement already satisfied: lark>=1.2.2 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.23)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.8)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.4.0)\n",
      "Requirement already satisfied: tzdata in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required Python packages\n",
    "%pip install \\\n",
    "  huggingface_hub \\\n",
    "  \"transformers>=4.36.0\" \\\n",
    "  peft \\\n",
    "  datasets \\\n",
    "  trl \\\n",
    "  jsonschema \\\n",
    "  litellm \\\n",
    "  \"jinja2>=3.1.0\" \\\n",
    "  \"torch>=2.0.0\" \\\n",
    "  openai \\\n",
    "  jupyterlab \\\n",
    "  requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a466d4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/meta-llama/llama-stack-client-python.git@main\n",
      "  Cloning https://github.com/meta-llama/llama-stack-client-python.git (to revision main) to /private/var/folders/n9/jvwmjx1j6vn5njz069y5lcn40000gn/T/pip-req-build-jru5edi4\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/meta-llama/llama-stack-client-python.git /private/var/folders/n9/jvwmjx1j6vn5njz069y5lcn40000gn/T/pip-req-build-jru5edi4\n",
      "  Resolved https://github.com/meta-llama/llama-stack-client-python.git to commit 254c646645024c4d51df9ae33a6f0992471a3e1a\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from llama_stack_client==0.4.0a11) (4.11.0)\n",
      "Requirement already satisfied: click in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from llama_stack_client==0.4.0a11) (8.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from llama_stack_client==0.4.0a11) (1.9.0)\n",
      "Requirement already satisfied: fire in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from llama_stack_client==0.4.0a11) (0.7.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from llama_stack_client==0.4.0a11) (0.28.1)\n",
      "Requirement already satisfied: pandas in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from llama_stack_client==0.4.0a11) (2.3.3)\n",
      "Requirement already satisfied: prompt-toolkit in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from llama_stack_client==0.4.0a11) (3.0.52)\n",
      "Requirement already satisfied: pyaml in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from llama_stack_client==0.4.0a11) (25.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from llama_stack_client==0.4.0a11) (2.12.4)\n",
      "Requirement already satisfied: requests in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from llama_stack_client==0.4.0a11) (2.32.5)\n",
      "Requirement already satisfied: rich in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from llama_stack_client==0.4.0a11) (14.2.0)\n",
      "Requirement already satisfied: sniffio in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from llama_stack_client==0.4.0a11) (1.3.1)\n",
      "Requirement already satisfied: termcolor in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from llama_stack_client==0.4.0a11) (3.2.0)\n",
      "Requirement already satisfied: tqdm in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from llama_stack_client==0.4.0a11) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from llama_stack_client==0.4.0a11) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->llama_stack_client==0.4.0a11) (3.11)\n",
      "Requirement already satisfied: certifi in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->llama_stack_client==0.4.0a11) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->llama_stack_client==0.4.0a11) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->llama_stack_client==0.4.0a11) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->llama_stack_client==0.4.0a11) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->llama_stack_client==0.4.0a11) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->llama_stack_client==0.4.0a11) (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from pandas->llama_stack_client==0.4.0a11) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from pandas->llama_stack_client==0.4.0a11) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from pandas->llama_stack_client==0.4.0a11) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from pandas->llama_stack_client==0.4.0a11) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama_stack_client==0.4.0a11) (1.17.0)\n",
      "Requirement already satisfied: wcwidth in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from prompt-toolkit->llama_stack_client==0.4.0a11) (0.2.14)\n",
      "Requirement already satisfied: PyYAML in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from pyaml->llama_stack_client==0.4.0a11) (6.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from requests->llama_stack_client==0.4.0a11) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from requests->llama_stack_client==0.4.0a11) (2.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from rich->llama_stack_client==0.4.0a11) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from rich->llama_stack_client==0.4.0a11) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->llama_stack_client==0.4.0a11) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade git+https://github.com/meta-llama/llama-stack-client-python.git@main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cd9d779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import requests\n",
    "from pprint import pprint\n",
    "from typing import Any, Dict, List, Union\n",
    "from time import sleep, time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import HfApi\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "583729b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "LlamaStack Server: http://localhost:8321\n",
      "Data Store: http://localhost:8001\n",
      "Entity Store: http://localhost:8002\n",
      "NIM: http://localhost:8006\n",
      "Namespace: xlam-tutorial-ns\n",
      "Base Model: meta/llama-3.2-1b-instruct\n"
     ]
    }
   ],
   "source": [
    "# Add parent directory to path to import config\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "from config import *\n",
    "\n",
    "# LlamaStack Server endpoint\n",
    "# LLAMASTACK_URL = \"http://localhost:8321\"\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"LlamaStack Server: {LLAMASTACK_URL}\")\n",
    "print(f\"Data Store: {NDS_URL}\")\n",
    "print(f\"Entity Store: {ENTITY_STORE_URL}\")\n",
    "print(f\"NIM: {NIM_URL}\")\n",
    "print(f\"Namespace: {NMS_NAMESPACE}\")\n",
    "print(f\"Base Model: {BASE_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09ae8305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0-alpha.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_stack_client import LlamaStackClient\n",
    "client = LlamaStackClient(base_url=LLAMASTACK_URL)\n",
    "client._version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d4660fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "LIMIT_TOOL_PROPERTIES = 8  # WAR for NIM bug with large tool properties\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "215a80b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directories created at: /Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/llamastack/e2e-test/server/data\n"
     ]
    }
   ],
   "source": [
    "# Processed data will be stored here\n",
    "DATA_ROOT = os.path.join(os.getcwd(), \"data\")\n",
    "CUSTOMIZATION_DATA_ROOT = os.path.join(DATA_ROOT, \"customization\")\n",
    "VALIDATION_DATA_ROOT = os.path.join(DATA_ROOT, \"validation\")\n",
    "EVALUATION_DATA_ROOT = os.path.join(DATA_ROOT, \"evaluation\")\n",
    "\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "os.makedirs(CUSTOMIZATION_DATA_ROOT, exist_ok=True)\n",
    "os.makedirs(VALIDATION_DATA_ROOT, exist_ok=True)\n",
    "os.makedirs(EVALUATION_DATA_ROOT, exist_ok=True)\n",
    "\n",
    "print(f\"Data directories created at: {DATA_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6350084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import HF_TOKEN\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://huggingface.co\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4053a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answers': '[{\"name\": \"live_giveaways_by_type\", \"arguments\": {\"type\": '\n",
      "            '\"beta\"}}, {\"name\": \"live_giveaways_by_type\", \"arguments\": '\n",
      "            '{\"type\": \"game\"}}]',\n",
      " 'id': 0,\n",
      " 'query': 'Where can I find live giveaways for beta access and games?',\n",
      " 'tools': '[{\"name\": \"live_giveaways_by_type\", \"description\": \"Retrieve live '\n",
      "          'giveaways from the GamerPower API based on the specified type.\", '\n",
      "          '\"parameters\": {\"type\": {\"description\": \"The type of giveaways to '\n",
      "          'retrieve (e.g., game, loot, beta).\", \"type\": \"str\", \"default\": '\n",
      "          '\"game\"}}}]'}\n"
     ]
    }
   ],
   "source": [
    "# Download from Hugging Face\n",
    "dataset = load_dataset(\"Salesforce/xlam-function-calling-60k\")\n",
    "\n",
    "# Inspect a sample\n",
    "example = dataset['train'][0]\n",
    "pprint(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5959da9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformation functions loaded successfully\n"
     ]
    }
   ],
   "source": [
    "def normalize_type(param_type: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize Python type hints to OpenAI function spec types.\n",
    "    \"\"\"\n",
    "    param_type = param_type.strip()\n",
    "\n",
    "    if \",\" in param_type and \"default\" in param_type:\n",
    "        param_type = param_type.split(\",\")[0].strip()\n",
    "\n",
    "    if param_type.startswith(\"default=\"):\n",
    "        return \"string\"\n",
    "\n",
    "    param_type = param_type.replace(\", optional\", \"\").strip()\n",
    "\n",
    "    if param_type.startswith(\"Callable\"):\n",
    "        return \"string\"\n",
    "    if param_type.startswith(\"Tuple\"):\n",
    "        return \"array\"\n",
    "    if param_type.startswith(\"List[\"):\n",
    "        return \"array\"\n",
    "    if param_type.startswith(\"Set\") or param_type == \"set\":\n",
    "        return \"array\"\n",
    "\n",
    "    type_mapping: Dict[str, str] = {\n",
    "        \"str\": \"string\",\n",
    "        \"int\": \"integer\",\n",
    "        \"float\": \"number\",\n",
    "        \"bool\": \"boolean\",\n",
    "        \"list\": \"array\",\n",
    "        \"dict\": \"object\",\n",
    "        \"List\": \"array\",\n",
    "        \"Dict\": \"object\",\n",
    "        \"set\": \"array\",\n",
    "        \"Set\": \"array\"\n",
    "    }\n",
    "\n",
    "    if param_type in type_mapping:\n",
    "        return type_mapping[param_type]\n",
    "    else:\n",
    "        print(f\"Unknown type: {param_type}\")\n",
    "        return \"string\"\n",
    "\n",
    "\n",
    "def convert_tools_to_openai_spec(tools: Union[str, List[Dict[str, Any]]]) -> List[Dict[str, Any]]:\n",
    "    if isinstance(tools, str):\n",
    "        try:\n",
    "            tools = json.loads(tools)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Failed to parse tools string as JSON: {e}\")\n",
    "            return []\n",
    "\n",
    "    if not isinstance(tools, list):\n",
    "        print(f\"Expected tools to be a list, but got {type(tools)}\")\n",
    "        return []\n",
    "\n",
    "    openai_tools: List[Dict[str, Any]] = []\n",
    "    for tool in tools:\n",
    "        if not isinstance(tool, dict):\n",
    "            print(f\"Expected tool to be a dictionary, but got {type(tool)}\")\n",
    "            continue\n",
    "\n",
    "        if not isinstance(tool.get(\"parameters\"), dict):\n",
    "            print(f\"Expected 'parameters' to be a dictionary for tool: {tool}\")\n",
    "            continue\n",
    "\n",
    "        normalized_parameters: Dict[str, Dict[str, Any]] = {}\n",
    "        for param_name, param_info in tool[\"parameters\"].items():\n",
    "            if not isinstance(param_info, dict):\n",
    "                print(f\"Expected parameter info to be a dictionary for: {param_name}\")\n",
    "                continue\n",
    "\n",
    "            param_dict = {\n",
    "                \"description\": param_info.get(\"description\", \"\"),\n",
    "                \"type\": normalize_type(param_info.get(\"type\", \"\")),\n",
    "            }\n",
    "\n",
    "            default_value = param_info.get(\"default\")\n",
    "            if default_value is not None and default_value != \"\":\n",
    "                param_dict[\"default\"] = default_value\n",
    "\n",
    "            normalized_parameters[param_name] = param_dict\n",
    "\n",
    "        openai_tool = {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": tool[\"name\"],\n",
    "                \"description\": tool[\"description\"],\n",
    "                \"parameters\": {\"type\": \"object\", \"properties\": normalized_parameters},\n",
    "            },\n",
    "        }\n",
    "        openai_tools.append(openai_tool)\n",
    "    return openai_tools\n",
    "\n",
    "\n",
    "def save_jsonl(filename, data):\n",
    "    \"\"\"Write a list of json objects to a .jsonl file\"\"\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        for entry in data:\n",
    "            f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "\n",
    "def convert_tool_calls(xlam_tools):\n",
    "    \"\"\"Convert XLAM tool format to OpenAI's tool schema.\"\"\"\n",
    "    tools = []\n",
    "    for tool in json.loads(xlam_tools):\n",
    "        tools.append({\"type\": \"function\", \"function\": {\"name\": tool[\"name\"], \"arguments\": tool.get(\"arguments\", {})}})\n",
    "    return tools\n",
    "\n",
    "\n",
    "def convert_example(example, dataset_type='single'):\n",
    "    \"\"\"Convert an XLAM dataset example to OpenAI format.\"\"\"\n",
    "    obj = {\"messages\": []}\n",
    "\n",
    "    obj[\"messages\"].append({\"role\": \"user\", \"content\": example[\"query\"]})\n",
    "\n",
    "    if example.get(\"tools\"):\n",
    "        obj[\"tools\"] = convert_tools_to_openai_spec(example[\"tools\"])\n",
    "\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    if example.get(\"answers\"):\n",
    "        tool_calls = convert_tool_calls(example[\"answers\"])\n",
    "        \n",
    "        if dataset_type == \"single\":\n",
    "            if len(tool_calls) == 1:\n",
    "                assistant_message[\"tool_calls\"] = tool_calls\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            assistant_message[\"tool_calls\"] = tool_calls\n",
    "                \n",
    "    obj[\"messages\"].append(assistant_message)\n",
    "\n",
    "    return obj\n",
    "\n",
    "\n",
    "def convert_example_eval(entry):\n",
    "    \"\"\"Convert a single entry to the evaluator format\"\"\"\n",
    "    # WAR for NIM bug with too many tool properties\n",
    "    for tool in entry[\"tools\"]:\n",
    "        if len(tool[\"function\"][\"parameters\"][\"properties\"]) > LIMIT_TOOL_PROPERTIES:\n",
    "            return None\n",
    "    \n",
    "    new_entry = {\n",
    "        \"messages\": [],\n",
    "        \"tools\": entry[\"tools\"],\n",
    "        \"tool_calls\": []\n",
    "    }\n",
    "    \n",
    "    for msg in entry[\"messages\"]:\n",
    "        if msg[\"role\"] == \"assistant\" and \"tool_calls\" in msg:\n",
    "            new_entry[\"tool_calls\"] = msg[\"tool_calls\"]\n",
    "        else:\n",
    "            new_entry[\"messages\"].append(msg)\n",
    "    \n",
    "    return new_entry\n",
    "\n",
    "\n",
    "def convert_dataset_eval(data):\n",
    "    \"\"\"Convert the entire dataset for evaluation.\"\"\"\n",
    "    return [result for entry in data if (result := convert_example_eval(entry)) is not None]\n",
    "\n",
    "\n",
    "def read_jsonl(file_path):\n",
    "    \"\"\"Reads a JSON Lines file and yields parsed JSON objects\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                yield json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "                continue\n",
    "\n",
    "print(\"Data transformation functions loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "903c72e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted example:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Test conversion on the example\n",
    "converted_example = convert_example(example)\n",
    "print(\"Converted example:\")\n",
    "pprint(converted_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00b17e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 28461 examples\n"
     ]
    }
   ],
   "source": [
    "# Convert all examples\n",
    "all_examples = []\n",
    "with open(os.path.join(DATA_ROOT, \"xlam_openai_format.jsonl\"), \"w\") as f:\n",
    "    for example in dataset[\"train\"]:\n",
    "        converted = convert_example(example)\n",
    "        if converted is not None:\n",
    "            all_examples.append(converted)\n",
    "            f.write(json.dumps(converted) + \"\\n\")\n",
    "\n",
    "print(f\"Converted {len(all_examples)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adda0f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split complete:\n",
      "  Training: 3500 examples\n",
      "  Validation: 750 examples\n",
      "  Test: 713 examples\n"
     ]
    }
   ],
   "source": [
    "# Configure dataset size\n",
    "NUM_EXAMPLES = 5000\n",
    "\n",
    "assert NUM_EXAMPLES <= len(all_examples), \\\n",
    "    f\"{NUM_EXAMPLES} exceeds the total number of available ({len(all_examples)}) data points\"\n",
    "\n",
    "# Randomly sample and split\n",
    "sampled_examples = random.sample(all_examples, NUM_EXAMPLES)\n",
    "\n",
    "train_size = int(0.7 * len(sampled_examples))\n",
    "val_size = int(0.15 * len(sampled_examples))\n",
    "\n",
    "train_data = sampled_examples[:train_size]\n",
    "val_data = sampled_examples[train_size : train_size + val_size]\n",
    "test_data = sampled_examples[train_size + val_size :]\n",
    "\n",
    "# Save splits\n",
    "save_jsonl(os.path.join(CUSTOMIZATION_DATA_ROOT, \"training.jsonl\"), train_data)\n",
    "save_jsonl(os.path.join(VALIDATION_DATA_ROOT, \"validation.jsonl\"), val_data)\n",
    "\n",
    "# Convert test data for evaluation\n",
    "test_data_eval = convert_dataset_eval(test_data)\n",
    "save_jsonl(os.path.join(EVALUATION_DATA_ROOT, \"xlam-test-single.jsonl\"), test_data_eval)\n",
    "\n",
    "print(f\"Dataset split complete:\")\n",
    "print(f\"  Training: {len(train_data)} examples\")\n",
    "print(f\"  Validation: {len(val_data)} examples\")\n",
    "print(f\"  Test: {len(test_data_eval)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "632e019c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity Store: 200\n",
      "Data Store: 201\n"
     ]
    }
   ],
   "source": [
    "def create_namespaces(entity_host, ds_host, namespace):\n",
    "    # Create namespace in Entity Store\n",
    "    entity_store_url = f\"{entity_host}/v1/namespaces\"\n",
    "    resp = requests.post(entity_store_url, json={\"id\": namespace})\n",
    "    assert resp.status_code in (200, 201, 409, 422), \\\n",
    "        f\"Unexpected response from Entity Store: {resp.status_code}\"\n",
    "    print(f\"Entity Store: {resp.status_code}\")\n",
    "\n",
    "    # Create namespace in Data Store\n",
    "    nds_url = f\"{ds_host}/v1/datastore/namespaces\"\n",
    "    resp = requests.post(nds_url, data={\"namespace\": namespace})\n",
    "    assert resp.status_code in (200, 201, 409, 422), \\\n",
    "        f\"Unexpected response from Data Store: {resp.status_code}\"\n",
    "    print(f\"Data Store: {resp.status_code}\")\n",
    "\n",
    "create_namespaces(entity_host=ENTITY_STORE_URL, ds_host=NDS_URL, namespace=NMS_NAMESPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1a246f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Store: 201\n",
      "{\n",
      "  \"namespace\": \"xlam-tutorial-ns\",\n",
      "  \"created_at\": \"2025-11-19T09:42:59Z\",\n",
      "  \"updated_at\": \"2025-11-19T09:42:59Z\"\n",
      "}\n",
      "\n",
      "Entity Store: 200\n",
      "{\n",
      "  \"id\": \"xlam-tutorial-ns\",\n",
      "  \"created_at\": \"2025-11-19T09:42:59.402383\",\n",
      "  \"updated_at\": \"2025-11-19T09:42:59.402385\",\n",
      "  \"description\": null,\n",
      "  \"project\": null,\n",
      "  \"custom_fields\": {},\n",
      "  \"ownership\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Verify namespaces\n",
    "res = requests.get(f\"{NDS_URL}/v1/datastore/namespaces/{NMS_NAMESPACE}\")\n",
    "print(f\"Data Store: {res.status_code}\")\n",
    "print(json.dumps(res.json(), indent=2))\n",
    "\n",
    "res = requests.get(f\"{ENTITY_STORE_URL}/v1/namespaces/{NMS_NAMESPACE}\")\n",
    "print(f\"\\nEntity Store: {res.status_code}\")\n",
    "print(json.dumps(res.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a496a632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository ID: xlam-tutorial-ns/xlam-ft-dataset\n",
      "Dataset repository created: xlam-tutorial-ns/xlam-ft-dataset\n"
     ]
    }
   ],
   "source": [
    "repo_id = f\"{NMS_NAMESPACE}/{DATASET_NAME}\"\n",
    "print(f\"Repository ID: {repo_id}\")\n",
    "\n",
    "hf_api = HfApi(endpoint=f\"{NDS_URL}/v1/hf\", token=\"\")\n",
    "\n",
    "# Create repo\n",
    "hf_api.create_repo(\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")\n",
    "\n",
    "print(f\"Dataset repository created: {repo_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1059c127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training.jsonl: 100%|| 6.06M/6.06M [00:04<00:00, 1.32MB/s]\n",
      "validation.jsonl: 100%|| 1.30M/1.30M [00:00<00:00, 7.37MB/s]\n",
      "xlam-test-single.jsonl: 100%|| 1.19M/1.19M [00:00<00:00, 6.81MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset files uploaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Upload dataset files\n",
    "train_fp = f\"{CUSTOMIZATION_DATA_ROOT}/training.jsonl\"\n",
    "val_fp = f\"{VALIDATION_DATA_ROOT}/validation.jsonl\"\n",
    "test_fp = f\"{EVALUATION_DATA_ROOT}/xlam-test-single.jsonl\"\n",
    "\n",
    "hf_api.upload_file(\n",
    "    path_or_fileobj=train_fp,\n",
    "    path_in_repo=\"training/training.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")\n",
    "\n",
    "hf_api.upload_file(\n",
    "    path_or_fileobj=val_fp,\n",
    "    path_in_repo=\"validation/validation.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")\n",
    "\n",
    "hf_api.upload_file(\n",
    "    path_or_fileobj=test_fp,\n",
    "    path_in_repo=\"testing/xlam-test-single.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")\n",
    "\n",
    "print(\"Dataset files uploaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9279ffd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n9/jvwmjx1j6vn5njz069y5lcn40000gn/T/ipykernel_4026/2898239522.py:7: DeprecationWarning: deprecated\n",
      "  response = client.beta.datasets.register(\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1beta/datasets \"HTTP/1.1 500 Internal Server Error\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Error code: 500 - {'detail': 'Internal server error: An unexpected error occurred.'}\n",
      "\n",
      " Dataset also registered in Entity Store (for customizer)!\n",
      "\n",
      " Dataset ready for fine-tuning: xlam-tutorial-ns/xlam-ft-dataset\n"
     ]
    }
   ],
   "source": [
    "# Register dataset via LlamaStack\n",
    "# Note: We register with localfs provider, but also need Entity Store for customizer\n",
    "# So we do both: LlamaStack registration + Entity Store registration\n",
    "\n",
    "# First: Register via LlamaStack client (for LlamaStack tracking)\n",
    "try:\n",
    "    response = client.beta.datasets.register(\n",
    "        dataset_id=f\"{NMS_NAMESPACE}/{DATASET_NAME}\",\n",
    "        purpose=\"post-training/messages\",\n",
    "        source={\n",
    "            \"type\": \"uri\",\n",
    "            \"uri\": f\"hf://datasets/{NMS_NAMESPACE}/{DATASET_NAME}\"\n",
    "        },\n",
    "        metadata={\n",
    "            \"description\": \"Tool calling xLAM dataset in OpenAI ChatCompletions format\",\n",
    "            \"project\": \"tool_calling\",\n",
    "            \"provider_id\": \"nvidia\"  # Hint for nvidia provider\n",
    "        }\n",
    "    )\n",
    "    print(\" Dataset registered via LlamaStack client!\")\n",
    "    print(f\"   ID: {response.identifier}\")\n",
    "    print(f\"   Provider: {response.provider_id}\")\n",
    "except Exception as e:\n",
    "    if '409' in str(e) or 'already exists' in str(e).lower():\n",
    "        print(\" Dataset already exists in LlamaStack - continuing...\")\n",
    "    else:\n",
    "        print(f\"Warning: {e}\")\n",
    "\n",
    "# Second: ALSO register in Entity Store (required for nvidia customizer)\n",
    "# The customizer queries Entity Store directly, not LlamaStack\n",
    "import requests\n",
    "response = requests.post(\n",
    "    f\"{ENTITY_STORE_URL}/v1/datasets\",\n",
    "    json={\n",
    "        \"name\": DATASET_NAME,\n",
    "        \"namespace\": NMS_NAMESPACE,\n",
    "        \"description\": \"Tool calling xLAM dataset in OpenAI ChatCompletions format\",\n",
    "        \"files_url\": f\"hf://datasets/{repo_id}\",\n",
    "        \"project\": \"tool_calling\",\n",
    "    },\n",
    ")\n",
    "\n",
    "if response.status_code in (200, 201):\n",
    "    print(\"\\n Dataset also registered in Entity Store (for customizer)!\")\n",
    "elif response.status_code == 409:\n",
    "    print(\"\\n Dataset already exists in Entity Store - continuing...\")\n",
    "else:\n",
    "    print(f\"\\n Entity Store registration failed: {response.status_code}\")\n",
    "    print(f\"   This may cause fine-tuning to fail.\")\n",
    "\n",
    "print(f\"\\n Dataset ready for fine-tuning: {NMS_NAMESPACE}/{DATASET_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8684bd65",
   "metadata": {},
   "source": [
    "# Part III: Fine-Tuning via LlamaStack\n",
    "\n",
    "Train a LoRA adapter using NeMo Customizer through the LlamaStack post-training API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79e92d",
   "metadata": {},
   "source": [
    "## Create Fine-Tuning Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a95986d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating fine-tuning job: xlam-ft-1763545400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1alpha/post-training/supervised-fine-tune \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fine-tuning job created successfully via LlamaStack client!\n",
      "Job UUID: cust-SicAnj7TGgfbjBGCnKMEW1\n",
      "Output Model: default/test-example-model@v1\n"
     ]
    }
   ],
   "source": [
    "# Create unique job ID\n",
    "import uuid\n",
    "from time import time\n",
    "unique_suffix = int(time())\n",
    "job_uuid = f\"xlam-ft-{unique_suffix}\"\n",
    "print(f\"Creating fine-tuning job: {job_uuid}\")\n",
    "\n",
    "# Submit fine-tuning job via LlamaStack client\n",
    "ft_job = client.alpha.post_training.supervised_fine_tune(\n",
    "    job_uuid=job_uuid,\n",
    "    model=f\"{BASE_MODEL}@v1.0.0+A100\",\n",
    "    training_config={\n",
    "        \"n_epochs\": 1,\n",
    "        \"data_config\": {\n",
    "            \"batch_size\": 8,\n",
    "            \"dataset_id\": DATASET_NAME,\n",
    "            \"shuffle\": True,\n",
    "            \"data_format\": \"instruct\"\n",
    "        },\n",
    "        \"optimizer_config\": {\n",
    "            \"optimizer_type\": \"adamw\",\n",
    "            \"lr\": 0.0001,\n",
    "            \"weight_decay\": 0.01,\n",
    "            \"num_warmup_steps\": 100\n",
    "        }\n",
    "    },\n",
    "    hyperparam_search_config={},\n",
    "    logger_config={},\n",
    "    algorithm_config={\n",
    "        \"type\": \"LoRA\",\n",
    "        \"rank\": 32,\n",
    "        \"alpha\": 16,\n",
    "        \"lora_attn_modules\": [],\n",
    "        \"apply_lora_to_mlp\": True,\n",
    "        \"apply_lora_to_output\": False,\n",
    "        \"use_dora\": False,\n",
    "        \"quantize_base\": False\n",
    "    },\n",
    "    checkpoint_dir=\"\"\n",
    ")\n",
    "\n",
    "print(\" Fine-tuning job created successfully via LlamaStack client!\")\n",
    "print(f\"Job UUID: {ft_job.job_uuid}\")\n",
    "\n",
    "# Store for later use - USE THE ACTUAL OUTPUT MODEL FROM RESPONSE\n",
    "JOB_ID = ft_job.job_uuid\n",
    "\n",
    "# Check if response has output_model field\n",
    "if hasattr(ft_job, 'output_model') and ft_job.output_model:\n",
    "    CUSTOMIZED_MODEL = ft_job.output_model\n",
    "    print(f\"Output Model: {CUSTOMIZED_MODEL}\")\n",
    "else:\n",
    "    # Fallback to constructed name\n",
    "    CUSTOMIZED_MODEL = f\"{NMS_NAMESPACE}/llama-3.2-1b-xlam@{job_uuid}\"\n",
    "    print(f\"Output Model (constructed): {CUSTOMIZED_MODEL}\")\n",
    "    print(f\" No output_model in response - using constructed name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecaa2c8",
   "metadata": {},
   "source": [
    "## Monitor Fine-Tuning Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c059ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring fine-tuning job: cust-SicAnj7TGgfbjBGCnKMEW1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0s] Status: in_progress | Epoch: 0 | Steps: 0/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30s] Status: in_progress | Epoch: 0 | Steps: 0/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61s] Status: in_progress | Epoch: 0 | Steps: 0/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[91s] Status: in_progress | Epoch: 0 | Steps: 0/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[122s] Status: in_progress | Epoch: 0 | Steps: 0/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[152s] Status: in_progress | Epoch: 0 | Steps: 0/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[183s] Status: in_progress | Epoch: 0 | Steps: 0/438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[213s] Status: in_progress | Epoch: 0 | Steps: 0/438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[244s] Status: in_progress | Epoch: 0 | Steps: 100/438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[274s] Status: in_progress | Epoch: 0 | Steps: 100/438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[305s] Status: in_progress | Epoch: 0 | Steps: 100/438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[335s] Status: in_progress | Epoch: 0 | Steps: 200/438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[366s] Status: in_progress | Epoch: 0 | Steps: 200/438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[396s] Status: in_progress | Epoch: 0 | Steps: 200/438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[427s] Status: in_progress | Epoch: 0 | Steps: 300/438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[457s] Status: in_progress | Epoch: 0 | Steps: 300/438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[488s] Status: in_progress | Epoch: 0 | Steps: 300/438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[518s] Status: in_progress | Epoch: 0 | Steps: 400/438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[548s] Status: in_progress | Epoch: 0 | Steps: 400/438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[579s] Status: in_progress | Epoch: 1 | Steps: 438/438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[609s] Status: in_progress | Epoch: 1 | Steps: 438/438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[640s] Status: completed | Epoch: 1 | Steps: 438/438\n",
      "\n",
      " Job completed with status: completed\n"
     ]
    }
   ],
   "source": [
    "def wait_customization_job(job_uuid: str, polling_interval: int = 30, timeout: int = 3600):\n",
    "    \"\"\"\n",
    "    Monitor a fine-tuning job until completion using LlamaStack client.\n",
    "    \"\"\"\n",
    "    start_time = time()\n",
    "    print(f\"Monitoring fine-tuning job: {job_uuid}\")\n",
    "    \n",
    "    while True:\n",
    "        elapsed = time() - start_time\n",
    "        if elapsed > timeout:\n",
    "            raise RuntimeError(f\"Job {job_uuid} exceeded timeout of {timeout}s\")\n",
    "        \n",
    "        # Get job status via LlamaStack client\n",
    "        jobs_response = client.alpha.post_training.job.list()\n",
    "        \n",
    "        # Handle both list and object with .data attribute\n",
    "        if isinstance(jobs_response, list):\n",
    "            jobs_list = jobs_response\n",
    "        elif hasattr(jobs_response, 'data'):\n",
    "            jobs_list = jobs_response.data\n",
    "        else:\n",
    "            jobs_list = [jobs_response]\n",
    "        \n",
    "        # Find our job\n",
    "        job_data = next((j for j in jobs_list if j.job_uuid == job_uuid), None)\n",
    "        \n",
    "        if not job_data:\n",
    "            print(f\"Warning: Job {job_uuid} not found\")\n",
    "            sleep(polling_interval)\n",
    "            continue\n",
    "        \n",
    "        job_status = job_data.status\n",
    "        \n",
    "        # Print progress\n",
    "        if hasattr(job_data, 'status_details') and job_data.status_details:\n",
    "            details = job_data.status_details\n",
    "            steps = details.get('steps_completed', 0)\n",
    "            total_steps = details.get('steps_per_epoch', 1)\n",
    "            epochs = details.get('epochs_completed', 0)\n",
    "            print(f\"[{elapsed:.0f}s] Status: {job_status} | Epoch: {epochs} | Steps: {steps}/{total_steps}\")\n",
    "        else:\n",
    "            print(f\"[{elapsed:.0f}s] Status: {job_status}\")\n",
    "        \n",
    "        # Check if job is complete\n",
    "        if job_status not in [\"scheduled\", \"in_progress\", \"created\", \"running\"]:\n",
    "            print(f\"\\n Job completed with status: {job_status}\")\n",
    "            return job_status\n",
    "        \n",
    "        sleep(polling_interval)\n",
    "\n",
    "# Start monitoring\n",
    "final_status = wait_customization_job(JOB_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e942b5d3",
   "metadata": {},
   "source": [
    "## Verify Customized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c80d7408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1/models \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models:\n",
      "  - nvidia/nv-rerank-qa-mistral-4b:1\n",
      "  - nvidia/nvidia/nv-rerankqa-mistral-4b-v3\n",
      "  - nvidia/nvidia/llama-3.2-nv-rerankqa-1b-v2\n",
      "\n",
      " Customized model 'default/test-example-model@v1' not yet in model list.\n",
      "   This is normal - the model may still be loading or may not appear in the list.\n",
      "   The nvidia provider can serve models not in the registry.\n",
      "\n",
      "   Let's test if it works for inference...\n"
     ]
    }
   ],
   "source": [
    "# List all available models via LlamaStack\n",
    "models_response = client.models.list()\n",
    "\n",
    "# Handle both list and object responses\n",
    "if isinstance(models_response, list):\n",
    "    models_list = models_response\n",
    "elif hasattr(models_response, 'data'):\n",
    "    models_list = models_response.data\n",
    "else:\n",
    "    models_list = [models_response]\n",
    "\n",
    "print(\"Available models:\")\n",
    "found_custom_model = False\n",
    "for model in models_list:\n",
    "    print(f\"  - {model.identifier}\")\n",
    "    # Check for customized model with or without nvidia/ prefix\n",
    "    if (CUSTOMIZED_MODEL in str(model.identifier) or \n",
    "        f\"nvidia/{CUSTOMIZED_MODEL}\" in str(model.identifier)):\n",
    "        print(f\"     Found our customized model!\")\n",
    "        found_custom_model = True\n",
    "\n",
    "if not found_custom_model:\n",
    "    print(f\"\\n Customized model '{CUSTOMIZED_MODEL}' not yet in model list.\")\n",
    "    print(f\"   This is normal - the model may still be loading or may not appear in the list.\")\n",
    "    print(f\"   The nvidia provider can serve models not in the registry.\")\n",
    "    print(f\"\\n   Let's test if it works for inference...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "729a7329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Entity Store for model: default/test-example-model@v1\n",
      "\n",
      "Found 1 models in Entity Store\n",
      "\n",
      " Found customized model in Entity Store!\n",
      "   Name: test-example-model@v1\n",
      "   Namespace: default\n",
      "   Status: upload_completed\n",
      "\n",
      "   Model details:\n",
      "{\n",
      "  \"created_at\": \"2025-11-19T09:43:21.838315\",\n",
      "  \"updated_at\": \"2025-11-19T09:43:21.838318\",\n",
      "  \"name\": \"test-example-model@v1\",\n",
      "  \"namespace\": \"default\",\n",
      "  \"description\": \"None\",\n",
      "  \"spec\": {\n",
      "    \"num_parameters\": 1000000000,\n",
      "    \"context_size\": 4096,\n",
      "    \"num_virtual_tokens\": 0,\n",
      "    \"is_chat\": true\n",
      "  },\n",
      "  \"artifact\": {\n",
      "    \"gpu_arch\": \"Ampere\",\n",
      "    \"precision\": \"bf16-mixed\",\n",
      "    \"tensor_parallelism\": 1,\n",
      "    \"backend_engine\": \"nemo\",\n",
      "    \"status\": \"upload_completed\",\n",
      "    \"files_url\": \"hf://default/test-example-model@v1\"\n",
      "  },\n",
      "  \"base_model\": \"meta/llama-3.2-1b-instruct\",\n",
      "  \"peft\": {\n",
      "    \"finetuning_type\": \"lora\"\n",
      "  },\n",
      "  \"schema_version\": \"1.0\",\n",
      "  \"project\": \"llamastack-project\",\n",
      "  \"custom_fields\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Check if model is registered in Entity Store\n",
    "import requests\n",
    "\n",
    "print(f\"Checking Entity Store for model: {CUSTOMIZED_MODEL}\\n\")\n",
    "\n",
    "# List all models in Entity Store\n",
    "response = requests.get(f\"{ENTITY_STORE_URL}/v1/models\")\n",
    "if response.status_code == 200:\n",
    "    models_data = response.json()\n",
    "    \n",
    "    # Handle different response formats\n",
    "    if isinstance(models_data, dict) and 'data' in models_data:\n",
    "        models = models_data['data']\n",
    "    elif isinstance(models_data, list):\n",
    "        models = models_data\n",
    "    else:\n",
    "        models = [models_data]\n",
    "    \n",
    "    print(f\"Found {len(models)} models in Entity Store\")\n",
    "    \n",
    "    # Look for our model\n",
    "    found = False\n",
    "    for model in models:\n",
    "        # Handle both string IDs and object responses\n",
    "        if isinstance(model, str):\n",
    "            model_id = model\n",
    "            # Check if our model name is in the ID\n",
    "            if CUSTOMIZED_MODEL in model_id or JOB_ID in model_id:\n",
    "                print(f\"\\n Found customized model in Entity Store!\")\n",
    "                print(f\"   Model ID: {model_id}\")\n",
    "                found = True\n",
    "                \n",
    "                # Get detailed info\n",
    "                detail_resp = requests.get(f\"{ENTITY_STORE_URL}/v1/models/{model_id}\")\n",
    "                if detail_resp.status_code == 200:\n",
    "                    print(f\"\\n   Model details:\")\n",
    "                    print(json.dumps(detail_resp.json(), indent=2))\n",
    "                break\n",
    "        elif isinstance(model, dict):\n",
    "            model_name = model.get('name', model.get('id', ''))\n",
    "            model_ns = model.get('namespace', '')\n",
    "            full_name = f\"{model_ns}/{model_name}\" if model_ns else model_name\n",
    "            \n",
    "            if CUSTOMIZED_MODEL in full_name or JOB_ID in str(model):\n",
    "                print(f\"\\n Found customized model in Entity Store!\")\n",
    "                print(f\"   Name: {model_name}\")\n",
    "                print(f\"   Namespace: {model_ns}\")\n",
    "                print(f\"   Status: {model.get('artifact', {}).get('status')}\")\n",
    "                print(f\"\\n   Model details:\")\n",
    "                print(json.dumps(model, indent=2))\n",
    "                found = True\n",
    "                break\n",
    "    \n",
    "    if not found:\n",
    "        print(f\"\\n Customized model NOT found in Entity Store!\")\n",
    "        print(f\"\\n   Looking for: {CUSTOMIZED_MODEL}\")\n",
    "        print(f\"   Or job ID: {JOB_ID}\")\n",
    "        print(f\"\\n   Available models:\")\n",
    "        for idx, model in enumerate(models[:20]):  # Show first 20\n",
    "            if isinstance(model, str):\n",
    "                print(f\"     {idx+1}. {model}\")\n",
    "            else:\n",
    "                model_id = model.get('name', model.get('id', 'unknown'))\n",
    "                print(f\"     {idx+1}. {model_id}\")\n",
    "        \n",
    "        print(f\"\\n    The Customizer may not have registered the model yet.\")\n",
    "        print(f\"   Check the customization job status and logs.\")\n",
    "else:\n",
    "    print(f\" Failed to query Entity Store: {response.status_code}\")\n",
    "    print(f\"   Response: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5bbfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX: Update CUSTOMIZED_MODEL to use the actual output model\n",
    "if our_job and hasattr(our_job, 'output_model'):\n",
    "    CUSTOMIZED_MODEL = our_job.output_model\n",
    "    print(f\" Updated CUSTOMIZED_MODEL to actual output: {CUSTOMIZED_MODEL}\")\n",
    "else:\n",
    "    print(f\" Could not get output_model from job\")\n",
    "    print(f\"   Current CUSTOMIZED_MODEL: {CUSTOMIZED_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e519db71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default/test-example-model@v1'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUSTOMIZED_MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93144db6",
   "metadata": {},
   "source": [
    "# Part IV: Model Evaluation via LlamaStack\n",
    "\n",
    "Evaluate both the base model and fine-tuned model using NeMo Evaluator through LlamaStack."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b1f3af",
   "metadata": {},
   "source": [
    "## Register Benchmark Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922e8968",
   "metadata": {},
   "source": [
    "### Register Base Model in Entity Store\n",
    "\n",
    "**Required for Evaluation**: The NeMo Evaluator fetches model information from Entity Store.\n",
    "We need to register the base model before running evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42543fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering base model in Entity Store: meta/llama-3.2-1b-instruct\n",
      "\n",
      " Base model registered in Entity Store!\n",
      "{\n",
      "  \"created_at\": \"2025-11-19T09:55:16.562102\",\n",
      "  \"updated_at\": \"2025-11-19T09:55:16.562104\",\n",
      "  \"name\": \"meta-llama-3.2-1b-instruct\",\n",
      "  \"namespace\": \"default\",\n",
      "  \"description\": \"Base Llama 3.2 1B Instruct model\",\n",
      "  \"spec\": {\n",
      "    \"num_parameters\": 1000000000,\n",
      "    \"context_size\": 4096,\n",
      "    \"num_virtual_tokens\": 0,\n",
      "    \"is_chat\": true\n",
      "  },\n",
      "  \"artifact\": {\n",
      "    \"gpu_arch\": \"Ampere\",\n",
      "    \"precision\": \"bf16-mixed\",\n",
      "    \"tensor_parallelism\": 1,\n",
      "    \"backend_engine\": \"nemo\",\n",
      "    \"status\": \"upload_completed\",\n",
      "    \"files_url\": \"nim://meta/llama-3.2-1b-instruct\"\n",
      "  },\n",
      "  \"base_model\": null,\n",
      "  \"api_endpoint\": null,\n",
      "  \"peft\": null,\n",
      "  \"prompt\": null,\n",
      "  \"guardrails\": null,\n",
      "  \"schema_version\": \"1.0\",\n",
      "  \"project\": \"tool_calling\",\n",
      "  \"custom_fields\": {},\n",
      "  \"ownership\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Register base model in Entity Store (required for evaluator)\n",
    "import requests\n",
    "\n",
    "print(f\"Registering base model in Entity Store: {BASE_MODEL}\\n\")\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{ENTITY_STORE_URL}/v1/models\",\n",
    "    json={\n",
    "        \"name\": BASE_MODEL.replace('/', '-'),  # Entity Store doesn't allow '/' in names\n",
    "        \"namespace\": \"default\",\n",
    "        \"description\": \"Base Llama 3.2 1B Instruct model\",\n",
    "        \"project\": \"tool_calling\",\n",
    "        \"spec\": {\n",
    "            \"num_parameters\": 1000000000,\n",
    "            \"context_size\": 4096,\n",
    "            \"num_virtual_tokens\": 0,\n",
    "            \"is_chat\": True\n",
    "        },\n",
    "        \"artifact\": {\n",
    "            \"gpu_arch\": \"Ampere\",\n",
    "            \"precision\": \"bf16-mixed\",\n",
    "            \"tensor_parallelism\": 1,\n",
    "            \"backend_engine\": \"nemo\",\n",
    "            \"status\": \"upload_completed\",\n",
    "            \"files_url\": f\"nim://{BASE_MODEL}\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "if response.status_code in (200, 201):\n",
    "    print(\" Base model registered in Entity Store!\")\n",
    "    print(json.dumps(response.json(), indent=2))\n",
    "elif response.status_code == 409:\n",
    "    print(\" Base model already exists in Entity Store - continuing...\")\n",
    "else:\n",
    "    print(f\" Failed to register base model: {response.status_code}\")\n",
    "    print(f\"Response: {response.text}\")\n",
    "    print(\"\\n Evaluation may fail without base model registration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55c9684e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n9/jvwmjx1j6vn5njz069y5lcn40000gn/T/ipykernel_4026/3297164248.py:32: DeprecationWarning: deprecated\n",
      "  benchmark = client.alpha.benchmarks.register(\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1alpha/eval/benchmarks \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Benchmark registered: xlam-tool-calling-eval\n"
     ]
    }
   ],
   "source": [
    "# Create benchmark for tool calling evaluation\n",
    "benchmark_id = \"xlam-tool-calling-eval\"\n",
    "\n",
    "benchmark_metadata = {\n",
    "    \"type\": \"custom\",\n",
    "    \"params\": {\"parallelism\": 8},\n",
    "    \"tasks\": {\n",
    "        \"tool-calling-accuracy\": {\n",
    "            \"type\": \"chat-completion\",\n",
    "            \"params\": {\n",
    "                \"template\": {\n",
    "                    \"messages\": \"{{ item.messages | tojson}}\",\n",
    "                    \"tools\": \"{{ item.tools | tojson }}\",\n",
    "                    \"tool_choice\": \"auto\"\n",
    "                }\n",
    "            },\n",
    "            \"dataset\": {\n",
    "                \"files_url\": f\"hf://datasets/{NMS_NAMESPACE}/{DATASET_NAME}/testing/xlam-test-single.jsonl\",\n",
    "                \"limit\": 50\n",
    "            },\n",
    "            \"metrics\": {\n",
    "                \"tool-calling-accuracy\": {\n",
    "                    \"type\": \"tool-calling\",\n",
    "                    \"params\": {\"tool_calls_ground_truth\": \"{{ item.tool_calls | tojson }}\"}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Register benchmark via LlamaStack\n",
    "benchmark = client.alpha.benchmarks.register(\n",
    "    benchmark_id=benchmark_id,\n",
    "    dataset_id=f\"{NMS_NAMESPACE}/{DATASET_NAME}\",\n",
    "    scoring_functions=[],\n",
    "    metadata=benchmark_metadata\n",
    ")\n",
    "\n",
    "print(f\" Benchmark registered: {benchmark_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "701d5bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_eval_job(benchmark_id: str, job_id: str, polling_interval: int = 10, timeout: int = 600):\n",
    "    \"\"\"\n",
    "    Monitor an evaluation job until completion.\n",
    "    \"\"\"\n",
    "    start_time = time()\n",
    "    print(f\"Monitoring evaluation job: {job_id}\\n\")\n",
    "    \n",
    "    while True:\n",
    "        elapsed = time() - start_time\n",
    "        if elapsed > timeout:\n",
    "            raise RuntimeError(f\"Evaluation {job_id} exceeded timeout of {timeout}s\")\n",
    "        \n",
    "        # Get job status via LlamaStack\n",
    "        job_status = client.alpha.eval.jobs.status(\n",
    "            benchmark_id=benchmark_id,\n",
    "            job_id=job_id\n",
    "        )\n",
    "        \n",
    "        status = job_status.status\n",
    "        print(f\"[{elapsed:.0f}s] Status: {status}\")\n",
    "        \n",
    "        if status not in [\"scheduled\", \"in_progress\"]:\n",
    "            print(f\"\\n Evaluation completed with status: {status}\")\n",
    "            \n",
    "            # Retrieve results\n",
    "            results = client.alpha.eval.jobs.retrieve(\n",
    "                benchmark_id=benchmark_id,\n",
    "                job_id=job_id\n",
    "            )\n",
    "            return results\n",
    "        \n",
    "        sleep(polling_interval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0857e652",
   "metadata": {},
   "source": [
    "## Evaluate Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9da05a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation of fine-tuned model: default/test-example-model@v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1alpha/eval/benchmarks/xlam-tool-calling-eval/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fine-tuned model evaluation started: eval-9x4GYzFoYhvYEG1rEzok7g\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation on fine-tuned model\n",
    "print(f\"Starting evaluation of fine-tuned model: {CUSTOMIZED_MODEL}\")\n",
    "\n",
    "ft_eval = client.alpha.eval.run_eval(\n",
    "    benchmark_id=benchmark_id,\n",
    "    benchmark_config={\n",
    "        \"eval_candidate\": {\n",
    "            \"type\": \"model\",\n",
    "            \"model\": CUSTOMIZED_MODEL,\n",
    "            \"sampling_params\": {\n",
    "                \"temperature\": 0.1,\n",
    "                \"top_p\": 0.7,\n",
    "                \"max_tokens\": 512\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "ft_eval_job_id = ft_eval.job_id\n",
    "print(f\" Fine-tuned model evaluation started: {ft_eval_job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38489de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/eval/benchmarks/xlam-tool-calling-eval/jobs/eval-9x4GYzFoYhvYEG1rEzok7g \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring evaluation job: eval-9x4GYzFoYhvYEG1rEzok7g\n",
      "\n",
      "[0s] Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/eval/benchmarks/xlam-tool-calling-eval/jobs/eval-9x4GYzFoYhvYEG1rEzok7g \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10s] Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/eval/benchmarks/xlam-tool-calling-eval/jobs/eval-9x4GYzFoYhvYEG1rEzok7g \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/eval/benchmarks/xlam-tool-calling-eval/jobs/eval-9x4GYzFoYhvYEG1rEzok7g/result \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21s] Status: completed\n",
      "\n",
      " Evaluation completed with status: completed\n"
     ]
    }
   ],
   "source": [
    "# Wait for fine-tuned model evaluation\n",
    "ft_results = wait_eval_job(benchmark_id, ft_eval_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4a6f90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fine-Tuned Model Results ===\n",
      "{\n",
      "  \"created_at\": \"2025-11-19T09:55:51.921981\",\n",
      "  \"updated_at\": \"2025-11-19T09:55:51.921982\",\n",
      "  \"id\": \"evaluation_result-9USmfdMrzcyMd3HuwbMHX8\",\n",
      "  \"job\": \"eval-9x4GYzFoYhvYEG1rEzok7g\",\n",
      "  \"tasks\": {\n",
      "    \"tool-calling-accuracy\": {\n",
      "      \"metrics\": {\n",
      "        \"tool-calling-accuracy\": {\n",
      "          \"scores\": {\n",
      "            \"function_name_accuracy\": {\n",
      "              \"value\": 0.96,\n",
      "              \"stats\": {\n",
      "                \"count\": 50,\n",
      "                \"sum\": 48.0,\n",
      "                \"mean\": 0.96\n",
      "              }\n",
      "            },\n",
      "            \"function_name_and_args_accuracy\": {\n",
      "              \"value\": 0.66,\n",
      "              \"stats\": {\n",
      "                \"count\": 50,\n",
      "                \"sum\": 33.0,\n",
      "                \"mean\": 0.66\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"groups\": {},\n",
      "  \"namespace\": \"default\",\n",
      "  \"custom_fields\": {}\n",
      "}\n",
      "\n",
      "Fine-Tuned Model Performance:\n",
      "  Function Name Accuracy: 96.0%\n",
      "  Function + Args Accuracy: 66.0%\n"
     ]
    }
   ],
   "source": [
    "# Extract and display fine-tuned model metrics\n",
    "# The results are in .scores, not .metrics\n",
    "ft_scores = ft_results.scores[benchmark_id]\n",
    "ft_aggregated = ft_scores.aggregated_results\n",
    "\n",
    "print(\"\\n=== Fine-Tuned Model Results ===\")\n",
    "print(json.dumps(ft_aggregated, indent=2))\n",
    "\n",
    "# Extract accuracy metrics\n",
    "task_results = ft_aggregated['tasks']['tool-calling-accuracy']\n",
    "metrics = task_results['metrics']['tool-calling-accuracy']['scores']\n",
    "\n",
    "ft_fn_accuracy = metrics['function_name_accuracy']['value']\n",
    "ft_fn_args_accuracy = metrics['function_name_and_args_accuracy']['value']\n",
    "\n",
    "print(f\"\\nFine-Tuned Model Performance:\")\n",
    "print(f\"  Function Name Accuracy: {ft_fn_accuracy:.1%}\")\n",
    "print(f\"  Function + Args Accuracy: {ft_fn_args_accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad1ee10",
   "metadata": {},
   "source": [
    "# Part V: Inference & Safety via LlamaStack\n",
    "\n",
    "Test the fine-tuned model with tool calling and apply safety guardrails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae268518",
   "metadata": {},
   "source": [
    "## Sample Inference with Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c982b14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 713 test samples\n",
      "\n",
      "Test query:\n",
      "  List the latest sold artworks from the 'Art Blocks' gallery, sorted by date sold.\n",
      "\n",
      "Available tools:\n",
      "  - expiry_date_enquiry: Queries the expiry date of a vehicle's license registration ...\n",
      "  - latest_sold: Fetches a list of recently sold artworks, with optional filt...\n",
      "  - search: Search for individuals by their last and optionally first na...\n"
     ]
    }
   ],
   "source": [
    "# Load test samples\n",
    "test_samples = list(read_jsonl(test_fp))\n",
    "print(f\"Loaded {len(test_samples)} test samples\")\n",
    "\n",
    "# Pick a random sample\n",
    "test_sample = random.choice(test_samples)\n",
    "print(\"\\nTest query:\")\n",
    "print(f\"  {test_sample['messages'][0]['content']}\")\n",
    "\n",
    "print(\"\\nAvailable tools:\")\n",
    "for tool in test_sample['tools']:\n",
    "    print(f\"  - {tool['function']['name']}: {tool['function']['description'][:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6b07b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Prediction ===\n",
      "Tool: latest_sold\n",
      "Arguments: {\"gallery\": \"Art Blocks\", \"sort\": \"date_sold\"}\n",
      "\n",
      "=== Ground Truth ===\n",
      "Tool: latest_sold\n",
      "Arguments: {'gallery': 'Art Blocks', 'sort': 'date_sold'}\n"
     ]
    }
   ],
   "source": [
    "# Run inference on fine-tuned model via LlamaStack\n",
    "response = client.chat.completions.create(\n",
    "    model=f\"nvidia/{CUSTOMIZED_MODEL}\",\n",
    "    messages=test_sample[\"messages\"],\n",
    "    tools=test_sample[\"tools\"],\n",
    "    tool_choice=\"auto\",\n",
    "    temperature=0.1,\n",
    "    top_p=0.7,\n",
    "    max_tokens=512,\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(\"\\n=== Model Prediction ===\")\n",
    "if response.choices[0].message.tool_calls:\n",
    "    for tc in response.choices[0].message.tool_calls:\n",
    "        print(f\"Tool: {tc.function.name}\")\n",
    "        print(f\"Arguments: {tc.function.arguments}\")\n",
    "else:\n",
    "    print(\"No tool calls generated\")\n",
    "\n",
    "print(\"\\n=== Ground Truth ===\")\n",
    "for tc in test_sample['tool_calls']:\n",
    "    print(f\"Tool: {tc['function']['name']}\")\n",
    "    print(f\"Arguments: {tc['function']['arguments']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
