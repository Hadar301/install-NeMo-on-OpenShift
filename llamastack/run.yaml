version: 2
image_name: nvidia
apis:
  - agents
  - datasetio
  - eval
  - files
  - inference
  - post_training
  - safety
  - scoring
  - tool_runtime
  - vector_io
providers:
  inference:
    - provider_id: nvidia
      provider_type: remote::nvidia
      config:
        url: ${env.NVIDIA_BASE_URL:=https://integrate.api.nvidia.com}
        api_key: ${env.NVIDIA_API_KEY}
        append_api_version: ${env.NVIDIA_APPEND_API_VERSION:=True}
  vector_io:
    - provider_id: faiss
      provider_type: inline::faiss
      config:
        persistence:
          backend: meta-reference
          namespace: default
  safety:
    - provider_id: nvidia
      provider_type: remote::nvidia
      config:
        guardrails_service_url: ${env.GUARDRAILS_SERVICE_URL:=http://guardrail.anemo-rhoai.svc.cluster.local:8000}
        config_id: ${env.NVIDIA_GUARDRAILS_CONFIG_ID:=self-check}
  agents:
    - provider_id: meta-reference
      provider_type: inline::meta-reference
      config:
        persistence:
          agent_state:
            backend: meta-reference
            namespace: default
            table_name: agent_state
          responses:
            backend: meta-reference-sql
            namespace: default
            table_name: agent_responses
  eval:
    - provider_id: nvidia
      provider_type: remote::nvidia
      config:
        evaluator_url: ${env.NVIDIA_EVALUATOR_URL:=http://evaluator.anemo-rhoai.svc.cluster.local:8000}
  post_training:
    - provider_id: nvidia
      provider_type: remote::nvidia
      config:
        api_key: ${env.NVIDIA_API_KEY:=}
        dataset_namespace: ${env.NVIDIA_DATASET_NAMESPACE:=default}
        project_id: ${env.NVIDIA_PROJECT_ID:=test-project}
        customizer_url: ${env.NVIDIA_CUSTOMIZER_URL:=http://nemo.test}
  datasetio:
    - provider_id: localfs
      provider_type: inline::localfs
      config:
        kvstore:
          backend: meta-reference
          namespace: default
          table_name: datasets
    - provider_id: nvidia
      provider_type: remote::nvidia
      config:
        api_key: ${env.NVIDIA_API_KEY:=}
        dataset_namespace: ${env.NVIDIA_DATASET_NAMESPACE:=default}
        project_id: ${env.NVIDIA_PROJECT_ID:=test-project}
        datasets_url: ${env.NVIDIA_DATASETS_URL:=http://nemodatastore-sample.anemo-rhoai.svc.cluster.local:8000}
  files:
    - provider_id: localfs
      provider_type: inline::localfs
      config:
        storage_dir: /tmp/files
        metadata_store:
          backend: meta-reference-sql
          namespace: default
          table_name: files
  scoring:
    - provider_id: basic
      provider_type: inline::basic
  tool_runtime:
    - provider_id: rag-runtime
      provider_type: inline::rag-runtime
storage:
  backends:
    meta-reference:
      type: kv_sqlite
      db_path: /tmp/storage_store.db
    meta-reference-sql:
      type: sql_sqlite
      db_path: /tmp/sql_storage_store.db
  stores:
    metadata:
      backend: meta-reference
      namespace: default
    conversations:
      backend: meta-reference-sql
      namespace: default
      table_name: conversations
    inference:
      backend: meta-reference-sql
      namespace: default
      table_name: inference
    prompts:
      backend: meta-reference
      namespace: default
models:
  - metadata: { }
    model_id: ${env.INFERENCE_MODEL}
    provider_id: nvidia
    model_type: llm
  - metadata: { }
    model_id: ${env.SAFETY_MODEL}
    provider_id: nvidia
    model_type: llm
shields:
  - shield_id: ${env.SAFETY_MODEL}
    provider_id: nvidia
vector_dbs: [ ]
datasets: [ ]
scoring_fns: [ ]
benchmarks: [ ]
tool_groups:
  - toolgroup_id: builtin::rag
    provider_id: rag-runtime
server:
  port: 8321
